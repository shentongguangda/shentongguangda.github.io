<!DOCTYPE html>
<html lang="zh-CN">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <title>Contrastive Search might-not-be What You Need - 第一桶鲸网站</title><meta name="Description" content="第一桶鲸"><meta property="og:title" content="Contrastive Search might-not-be What You Need" />
<meta property="og:description" content="TL;DR

GPT-NeoX-20B appears to be anisotropic (Isotropy: 0.197)
Int8 quantisation appears to have ~no effect on isotropy
I am new to ML so the above could be false, feel free to poke at my findings here
" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://shentongguangda.github.io/survey/anisotropy/" /><meta property="og:image" content="https://shentongguangda.github.io/logo.jpg"/><meta property="article:section" content="survey" />
<meta property="article:published_time" content="2022-12-12T19:08:08+08:00" />
<meta property="article:modified_time" content="2022-12-12T21:08:08+08:00" /><meta property="og:site_name" content="第一桶鲸" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://shentongguangda.github.io/logo.jpg"/>

<meta name="twitter:title" content="Contrastive Search might-not-be What You Need"/>
<meta name="twitter:description" content="TL;DR

GPT-NeoX-20B appears to be anisotropic (Isotropy: 0.197)
Int8 quantisation appears to have ~no effect on isotropy
I am new to ML so the above could be false, feel free to poke at my findings here
"/>
<meta name="application-name" content="第一桶鲸">
<meta name="apple-mobile-web-app-title" content="第一桶鲸"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://shentongguangda.github.io/survey/anisotropy/" /><link rel="prev" href="https://shentongguangda.github.io/survey/an-informal-reminder/" /><link rel="next" href="https://shentongguangda.github.io/survey/tortoise-tts-fast/" /><link rel="stylesheet" href="/css/style.min.css"><link rel="preload" href="/lib/fontawesome-free/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"></noscript><link rel="preload" href="/lib/animate/animate.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="/lib/animate/animate.min.css"></noscript><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "Contrastive Search might-not-be What You Need",
        "inLanguage": "zh-CN",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/shentongguangda.github.io\/survey\/anisotropy\/"
        },"genre": "survey","keywords": "machine learning, language models, research","wordcount":  799 ,
        "url": "https:\/\/shentongguangda.github.io\/survey\/anisotropy\/","datePublished": "2022-12-12T19:08:08+08:00","dateModified": "2022-12-12T21:08:08+08:00","publisher": {
            "@type": "Organization",
            "name": ""},"author": {
                "@type": "Person",
                "name": "152334H"
            },"description": ""
    }
    </script></head>
    <body data-header-desktop="fixed" data-header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="第一桶鲸网站">第一桶鲸</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/" title="苹果试玩"> 苹果试玩 </a><a class="menu-item" href="/survey/" title="调查网站"> 调查网站 </a><a class="menu-item" href="/trade/" title="交易所"> 交易所 </a><a class="menu-item" href="/tags/" title="标签"> 标签 </a><a class="menu-item" href="/categories/" title="分类"> 分类 </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="Search">
                            <i class="fas fa-search fa-fw" aria-hidden="true"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="Clear">
                            <i class="fas fa-times-circle fa-fw" aria-hidden="true"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
                </a></div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="第一桶鲸网站">第一桶鲸</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="Search">
                            <i class="fas fa-search fa-fw" aria-hidden="true"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="Clear">
                            <i class="fas fa-times-circle fa-fw" aria-hidden="true"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        Cancel
                    </a>
                </div><a class="menu-item" href="/posts/" title="苹果试玩">苹果试玩</a><a class="menu-item" href="/survey/" title="调查网站">调查网站</a><a class="menu-item" href="/trade/" title="交易所">交易所</a><a class="menu-item" href="/tags/" title="标签">标签</a><a class="menu-item" href="/categories/" title="分类">分类</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
            </a></div>
    </div>
</header><div class="search-dropdown desktop">
        <div id="search-dropdown-desktop"></div>
    </div>
    <div class="search-dropdown mobile">
        <div id="search-dropdown-mobile"></div>
    </div><main class="main">
                <div class="container"><div class="page single special"><h1 class="single-title animate__animated animate__pulse animate__faster">Contrastive Search might-not-be What You Need</h1><h2 class="single-subtitle">&lt;span style=color:grey&gt;Alt title: &lt;i&gt;Please help me fact-check my code&lt;/i&gt;&lt;/span&gt;</h2><div class="content" id="content"><h4>TL;DR</h4>
<ul>
<li><u><strong>GPT-NeoX-20B appears to be anisotropic</strong></u> (Isotropy: 0.197)</li>
<li>Int8 quantisation appears to have ~no effect on isotropy</li>
<li>I am new to ML so the above could be false, feel free to poke at my findings <a href="https://github.com/152334H/Contrastive_Search_Is_What_You_Need/tree/main/isotropy_analysis" target="_blank" rel="noopener noreffer ">here</a></li>
</ul>
<h1 id="evaluating-the-isotropy-of-more-language-models">Evaluating the isotropy of more language models</h1>
<p>In <a href="https://arxiv.org/abs/2210.14140" target="_blank" rel="noopener noreffer "><em>Contrastive Search Is What You Need For Neural Text Generation</em></a>, it is argued that</p>
<blockquote>
<p>through extensive evaluations on a wide range of LMs with different scales, we empirically show that the English autoregressive LMs are naturally isotropic,</p>
</blockquote>
<p align="center">
<img width=299 src="cool_graph.png">
<p align="center" style="color:grey">They also show a cool graph representing this finding</p>
</p>
<p>Do I have any idea what that means? <em>Nope.</em> I know that it makes <a href="https://huggingface.co/blog/introducing-csearch" target="_blank" rel="noopener noreffer ">contrastive search</a> useful, but I don&rsquo;t grasp any of the mathematics.</p>
<p>What I did find out: the evaluation harness for isotropy used in the paper is <a href="https://github.com/yxuansu/Contrastive_Search_Is_What_You_Need/tree/main/isotropy_analysis" target="_blank" rel="noopener noreffer ">open source</a> and very easy to install! So I decided to try running it on a few models that were absent in the paper.</p>
<h2 id="gpt-j-6b">GPT-J-6B</h2>
<p>I&rsquo;m already working on a <a href="https://github.com/152334H/gpt-j-editor" target="_blank" rel="noopener noreffer ">project</a> with GPT-J, so I started with it.</p>
<p>Getting the isotropy evaluation code installed is simple.</p>
<div class="details admonition note">
        <div class="details-summary admonition-title">
            <i class="icon fas fa-pencil-alt fa-fw" aria-hidden="true"></i>Installation and setup<i class="details-icon fas fa-angle-right fa-fw" aria-hidden="true"></i>
        </div>
        <div class="details-content">
            <div class="admonition-content"><h4 id="setup-conda-env">Setup conda env</h4>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">conda create -n csearch <span class="nv">python</span><span class="o">=</span>3.9
</span></span><span class="line"><span class="cl">conda activate csearch
</span></span><span class="line"><span class="cl">conda install pytorch torchvision torchaudio pytorch-cuda<span class="o">=</span>11.7 -c pytorch -c nvidia
</span></span><span class="line"><span class="cl">pip install simctg
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="clone-repo--extract-dataset">Clone repo &amp; extract dataset</h4>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">git clone https://github.com/yxuansu/Contrastive_Search_Is_What_You_Need
</span></span><span class="line"><span class="cl"><span class="nb">cd</span> Contrastive_Search_Is_What_You_Need/data
</span></span><span class="line"><span class="cl">unzip wit.zip
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="add-code-for-new-gpt-model">Add code for new GPT model</h4>
<p>After getting the evaluation code installed, I edited the code to work for GPT-J, as shown in <a href="https://github.com/152334H/Contrastive_Search_Is_What_You_Need/commit/f1d609201aff2936a4fd56f12a22ed27b5633a34" target="_blank" rel="noopener noreffer ">this commit</a>.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-diff" data-lang="diff"><span class="line"><span class="cl"><span class="gh">diff --git a/isotropy_analysis/compute_language_model_isotropy.py b/isotropy_analysis/compute_language_model_isotropy.py
</span></span></span><span class="line"><span class="cl"><span class="gh">index 44b6ed1..6c83641 100644
</span></span></span><span class="line"><span class="cl"><span class="gh"></span><span class="gd">--- a/isotropy_analysis/compute_language_model_isotropy.py
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gi">+++ b/isotropy_analysis/compute_language_model_isotropy.py
</span></span></span><span class="line"><span class="cl"><span class="gi"></span><span class="gu">@@ -25,7 +25,7 @@ def parse_text(text, tokenizer, max_len, bos_token_id=None):
</span></span></span><span class="line"><span class="cl"><span class="gu"></span><span class="gi">+    if &#39;gpt-neo&#39; in model_name or &#39;gpt-j&#39; in model_name:
</span></span></span><span class="line"><span class="cl"><span class="gi"></span><span class="gd">-    if &#39;gpt-neo&#39; in model_name:
</span></span></span><span class="line"><span class="cl"><span class="gd"></span><span class="gu">@@ -63,24 +63,12 @@ if __name__ == &#39;__main__&#39;:
</span></span></span><span class="line"><span class="cl"><span class="gu"></span><span class="gi">+    elif &#39;gpt-j&#39; in model_name:
</span></span></span><span class="line"><span class="cl"><span class="gi">+        print(&#39;Evaluating GPT-J model&#39;)
</span></span></span><span class="line"><span class="cl"><span class="gi">+        from transformers import GPTJForCausalLM, AutoTokenizer
</span></span></span><span class="line"><span class="cl"><span class="gi">+        model = GPTJForCausalLM.from_pretrained(model_name, revision=&#34;float16&#34;, torch_dtype=torch.float16, low_cpu_mem_usage=True)
</span></span></span><span class="line"><span class="cl"><span class="gi">+        tokenizer = AutoTokenizer.from_pretrained(model_name)
</span></span></span><span class="line"><span class="cl"><span class="gi">+        bos_token_id = None
</span></span></span></code></pre></td></tr></table>
</div>
</div></div>
        </div>
    </div>
<p>Result:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">$ ./inference.sh
</span></span><span class="line"><span class="cl">Evaluating GPT-J model
</span></span><span class="line"><span class="cl">Model loaded!
</span></span><span class="line"><span class="cl">Loading data...
</span></span><span class="line"><span class="cl">Data loaded!
</span></span><span class="line"><span class="cl">Performing inference...
</span></span><span class="line"><span class="cl">100% <span class="p">|</span><span class="c1">#######################################################|</span>
</span></span><span class="line"><span class="cl">Inference completed!
</span></span><span class="line"><span class="cl">Language Code:en, Model:EleutherAI/gpt-j-6B, Isotropy:0.69
</span></span></code></pre></td></tr></table>
</div>
</div><p><code>0.69</code> is about what you&rsquo;d expect from the paper, no surprise there.</p>
<h2 id="gpt-neox-20b">GPT-NeoX-20B</h2>
<p>My hardware setup is limited to an RTX 3090, so the only way I can run NeoX-20B (without more money) is to load it with <a href="https://huggingface.co/blog/hf-bitsandbytes-integration" target="_blank" rel="noopener noreffer ">LLM.int8()</a>.</p>
<p>I eventually achieve that after some debugging:</p>
<div class="details admonition note">
        <div class="details-summary admonition-title">
            <i class="icon fas fa-pencil-alt fa-fw" aria-hidden="true"></i>Debugging problems<i class="details-icon fas fa-angle-right fa-fw" aria-hidden="true"></i>
        </div>
        <div class="details-content">
            <div class="admonition-content"><p>Working from <a href="https://github.com/152334H/Contrastive_Search_Is_What_You_Need/commit/f1d609201aff2936a4fd56f12a22ed27b5633a34" target="_blank" rel="noopener noreffer ">the same commit</a>, I get a strange result:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">$ ./inference.sh
</span></span><span class="line"><span class="cl">Evaluating GPT-NeoX model
</span></span><span class="line"><span class="cl">Model loaded!
</span></span><span class="line"><span class="cl">Loading data...
</span></span><span class="line"><span class="cl">Data loaded!
</span></span><span class="line"><span class="cl">Performing inference...
</span></span><span class="line"><span class="cl">100% <span class="p">|</span><span class="c1">#######################################################|</span>
</span></span><span class="line"><span class="cl">Inference completed!
</span></span><span class="line"><span class="cl">Language Code:en, Model:EleutherAI/gpt-j-6B, Isotropy:nan
</span></span></code></pre></td></tr></table>
</div>
</div><p><code>nan</code>. The bane of Machine Learning. I&rsquo;m 99% certain this is wrong in some way, so I add print statements everywhere.</p>
<p>Eventually, I notice that the <code>last_hidden_states</code> of the model&rsquo;s forward pass looks like this:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">tensor<span class="o">([[[</span>nan, nan, nan,  ..., nan, nan, nan<span class="o">]</span>,                                                             <span class="p">|</span>
</span></span><span class="line"><span class="cl">         <span class="o">[</span>nan, nan, nan,  ..., nan, nan, nan<span class="o">]</span>,
</span></span><span class="line"><span class="cl">         <span class="o">[</span>nan, nan, nan,  ..., nan, nan, nan<span class="o">]</span>,
</span></span><span class="line"><span class="cl">         <span class="o">[</span>nan, nan, nan,  ..., nan, nan, nan<span class="o">]</span>,
</span></span><span class="line"><span class="cl">         <span class="o">[</span>nan, nan, nan,  ..., nan, nan, nan<span class="o">]</span>,
</span></span><span class="line"><span class="cl">         <span class="o">[</span>nan, nan, nan,  ..., nan, nan, nan<span class="o">]]]</span>, <span class="nv">device</span><span class="o">=</span><span class="s1">&#39;cuda:0&#39;</span>,
</span></span><span class="line"><span class="cl">       <span class="nv">dtype</span><span class="o">=</span>torch.float16<span class="o">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>And that if I call the model right after <code>model.eval()</code>, I get this:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">tensor<span class="o">([[[</span>-0.1514,  1.2617, -0.0116,  ..., -0.1769, -1.2178,  0.0608<span class="o">]</span>,
</span></span><span class="line"><span class="cl">         <span class="o">[</span>-0.8823, -0.5493, -0.0648,  ...,  0.1132, -3.9043,  0.0745<span class="o">]</span>,
</span></span><span class="line"><span class="cl">         <span class="o">[</span> 0.6362,  0.8086,  0.0204,  ...,  0.0682, -5.6445,  0.2147<span class="o">]</span>,
</span></span><span class="line"><span class="cl">         <span class="o">[</span>-0.1072,  1.6904, -1.4424,  ...,  0.1148,  0.1061, -1.3096<span class="o">]]]</span>,
</span></span><span class="line"><span class="cl">       <span class="nv">device</span><span class="o">=</span><span class="s1">&#39;cuda:0&#39;</span>, <span class="nv">dtype</span><span class="o">=</span>torch.float16, <span class="nv">grad_fn</span><span class="o">=</span>&lt;NativeLayerNormBackward0&gt;<span class="o">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Eventually, I figure out the <a href="https://github.com/152334H/Contrastive_Search_Is_What_You_Need/blob/f1d609201aff2936a4fd56f12a22ed27b5633a34/isotropy_analysis/compute_language_model_isotropy.py#L92" target="_blank" rel="noopener noreffer ">line of code</a> that&rsquo;s responsible:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">cuda_available</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="c1"># model() produces NaN tensor after this line</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>The model is initialised with <code>device_map='auto'</code>, which puts the model on <code>device='cuda:0'</code> on my machine, which should be equivalent to the <code>device</code> in the above line.</p>
<p><strong>I do not understand</strong> why the above line causes everything to go to <code>nan</code>, but I also do not think it is related to the result later on, because this problem occurs in other models (e.g. GPT-J-6B) as well.</p>
<p>I&rsquo;m leaving this information here in case I happen to be wrong.</p>
</div>
        </div>
    </div>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">$ ./inference.sh
</span></span><span class="line"><span class="cl">Evaluating EleutherAI/gpt-neox-20b
</span></span><span class="line"><span class="cl">Model loaded!
</span></span><span class="line"><span class="cl">Loading data...
</span></span><span class="line"><span class="cl">Data loaded!
</span></span><span class="line"><span class="cl">Performing inference...
</span></span><span class="line"><span class="cl">100% <span class="p">|</span><span class="c1">##############################################|</span>
</span></span><span class="line"><span class="cl">Inference completed!
</span></span><span class="line"><span class="cl">Language Code:en, Model:EleutherAI/gpt-neox-20b, Isotropy:0.1973011465713972
</span></span></code></pre></td></tr></table>
</div>
</div><p>And this is the reason why I bothered to write this post at all. <strong>8bit GPT-NeoX-20B</strong>, as evaluated on my machine, appears to be <strong>anisotropic</strong>.</p>
<h2 id="is-int8-the-problem">Is Int8 the problem?</h2>
<p>Probably not.</p>
<p align="center">
<img src="results.png">
</p>
<p>I tested int8 quantisised vs fp16/fp32 models, and got mostly identical results.</p>
<p>I can&rsquo;t rule out the possibility that my code/hardware is broken specifically for NeoX-20B, but I think the experiments I&rsquo;ve done are strong indicators that bugged code is probably not the cause of the observed anisotropy.</p></div></div></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">Powered by <a href="https://gohugo.io/" target="_blank" rel="noopener noreffer" title="Hugo 0.120.1">Hugo</a> | Theme - <a href="https://github.com/dillonzq/LoveIt" target="_blank" rel="noopener noreffer" title="LoveIt 0.2.11"><i class="far fa-kiss-wink-heart fa-fw" aria-hidden="true"></i> LoveIt</a>
                </div><div class="footer-line" itemscope itemtype="http://schema.org/CreativeWork"><i class="far fa-copyright fa-fw" aria-hidden="true"></i><span itemprop="copyrightYear">2023</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="https://shentongguangda.github.io" target="_blank">第一桶鲸</a></span>&nbsp;|&nbsp;<span class="license"><a rel="license external nofollow noopener noreffer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw" aria-hidden="true"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw" aria-hidden="true"></i>
            </a>
        </div><link rel="stylesheet" href="/lib/katex/katex.min.css"><link rel="stylesheet" href="/lib/cookieconsent/cookieconsent.min.css"><script type="text/javascript" src="/lib/autocomplete/autocomplete.min.js"></script><script type="text/javascript" src="/lib/lunr/lunr.min.js"></script><script type="text/javascript" src="/lib/lazysizes/lazysizes.min.js"></script><script type="text/javascript" src="/lib/clipboard/clipboard.min.js"></script><script type="text/javascript" src="/lib/sharer/sharer.min.js"></script><script type="text/javascript" src="/lib/katex/katex.min.js"></script><script type="text/javascript" src="/lib/katex/contrib/auto-render.min.js"></script><script type="text/javascript" src="/lib/katex/contrib/copy-tex.min.js"></script><script type="text/javascript" src="/lib/katex/contrib/mhchem.min.js"></script><script type="text/javascript" src="/lib/cookieconsent/cookieconsent.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":50},"comment":{},"cookieconsent":{"content":{"dismiss":"Got it!","link":"Learn more","message":"This website uses Cookies to improve your experience."},"enable":true,"palette":{"button":{"background":"#f0f0f0"},"popup":{"background":"#1aa3ff"}},"theme":"edgeless"},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":true,"left":"\\begin{equation}","right":"\\end{equation}"},{"display":true,"left":"\\begin{equation*}","right":"\\end{equation*}"},{"display":true,"left":"\\begin{align}","right":"\\end{align}"},{"display":true,"left":"\\begin{align*}","right":"\\end{align*}"},{"display":true,"left":"\\begin{alignat}","right":"\\end{alignat}"},{"display":true,"left":"\\begin{alignat*}","right":"\\end{alignat*}"},{"display":true,"left":"\\begin{gather}","right":"\\end{gather}"},{"display":true,"left":"\\begin{CD}","right":"\\end{CD}"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"highlightTag":"em","lunrIndexURL":"/index.json","maxResultLength":10,"noResultsFound":"No results found","snippetLength":50,"type":"lunr"}};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
